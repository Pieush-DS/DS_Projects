# -*- coding: utf-8 -*-
"""Pieush_Logistic+Regression_Telecom_Churn_Rate_Final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1S6VVLHp8aGfms3uXtT_QU1X--3pOw4K5

# <font color = blue> Telecomm Churn with Logistic Regression  </font>
### Problem Statement:

Telecomm industry is highly competitive and customers actively switch from one operator to another, the telecommunications industry experiences an average of 15-25% annual churn rate and it costs 5-10 times more to acquire a new customer than to retain an existing one, customer retention has now become even more important than customer acquisition.
 
For many telecomm operators, retaining high profitable customers is the number one business goal.

To reduce customer churn, telecom companies need to predict which customers are at high risk of churn.

**Definitions of churn**

**a) Revenue-based churn**: Customers who have not utilised any revenue-generating facilities such as mobile internet, outgoing calls, SMS etc. over a given period of time. 

**b) Usage-based churn**: Customers who have not done any usage, either incoming or outgoing - in terms of calls, internet etc. over a period of time.

A potential shortcoming of this definition is that when the customer has stopped using the services for a while, it may be too late to take any corrective actions to retain them. For e.g., if you define churn based on a ‘two-months zero usage’ period, predicting churn could be useless since by that time the customer would have already switched to another operator.

**High-value churn**
In the Indian and the Southeast Asian market, approximately 80% of revenue comes from the top 20% customers (called high-value customers). Thus, if we can reduce churn of the high-value customers, we will be able to reduce significant revenue leakage.

 
**Therefore in this project...** 

A) Need to analyse customer-level data of a leading telecom firm, build predictive models to identify customers at high risk of churn and identify the main indicators of churn.

B) Need to define high-value customers based on a certain metric (mentioned later below) and predict churn only on high-value customers.

C) Use the usage-based definition to define churn.

The dataset contains customer-level information for a span of four consecutive months - June, July, August and September. The months are encoded as 6, 7, 8 and 9, respectively.

### Business Goal:
A) Predict the churn in the last (i.e. the ninth) month using the data (features) from the first three months. 
  This can be done well, by understanding the typical customer behaviour during churn.

- In churn prediction, there are basically three phases of customer lifecycle :

 I) ‘Good’ phase: In this phase, the customer is happy with the service and behaves as usual.

 II) 'Action’ phase: The customer experience starts to sore in this phase, for e.g. he/she gets a compelling offer from a  competitor, faces unjust charges, becomes unhappy with service quality etc. In this phase, the customer usually shows different behaviour than the ‘Good’ months. Also, it is crucial to identify high-churn-risk customers in this phase, since some corrective actions can be taken at this point (such as matching the competitor’s offer/improving the service quality etc.)

 III) 'Churn’ phase: Churn can be defined based on this phase. Also, it is important to note that at the time of prediction (i.e. the action months), this data is not available to you for prediction. Thus, after tagging churn as 1/0 based on this phase, discard all data corresponding to this phase.



- In this case, since there are four-month window, the first two months are the ‘Good’ phase, the third month is the ‘Action’ phase, while the fourth month is the ‘Churn’ phase.

#### Steps to Follow...
1. Reading necessary data

2. Understanding Data

3. Cleaning of the Dataset

4. Data Preparation

5. EDA (Visualising the Data)

6. Splitting the Data into Training and Testing Sets

7. Feature Scaling

8. Building Various Models and their analysis for Model selection
   - A) RFE with Logistic Regression
   - B) Random Forest with Logistic Regression
   - C) XGBoost with Logistic Regression
   - D) Ridge Regression
   - E) PCA with Logistic Regression

9. Feature Selection using any final model

10. Conclusion
"""

from google.colab import drive
drive.mount('/content/drive')

# pip install pysurvival

"""#### Calling various essential library functions"""

# Suppressing Warnings
import warnings
warnings.filterwarnings('ignore')

# Commented out IPython magic to ensure Python compatibility.
# Importing the required libraries
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import time
import xgboost as xgb
# import shap

from scipy import stats
from datetime import datetime

import statsmodels
import statsmodels.api as sm
import sklearn
import pydotplus, graphviz

from collections import OrderedDict
from itertools import islice

from sklearn import model_selection
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score
from statsmodels.stats.outliers_influence import variance_inflation_factor #Check for the VIF values of the feature variables. 
from sklearn.feature_selection import RFE
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn import metrics
from numpy import percentile
# from lifelines.utils import concordance_index

from statsmodels.stats.outliers_influence import variance_inflation_factor
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score, recall_score
from sklearn.metrics import precision_recall_curve
from sklearn.metrics import classification_report
from sklearn.neighbors import KNeighborsClassifier
from sklearn.decomposition import IncrementalPCA
from sklearn.decomposition import PCA

from sklearn.model_selection import cross_val_score
from sklearn.model_selection import KFold
from sklearn.model_selection import GridSearchCV
from sklearn.pipeline import make_pipeline
from sklearn.linear_model import LinearRegression, Ridge, Lasso

from imblearn.over_sampling import SMOTE
from sklearn.utils import resample

from IPython.display import Image  
from six import StringIO  
from sklearn.tree import export_graphviz
# from pandas_profiling import ProfileReport

# %matplotlib inline

# To set the Row, Column and Width of the Dataframe to show on Jupyter Notebook
pd.set_option('display.max_rows', None)
pd.set_option('display.max_columns', None)
pd.set_option('display.max_colwidth', None)

"""### Step 1: Importing and Reading the Data"""

# Importing all datasets and to store in a Pandas Dataframe
Tele_Churn_colab = pd.read_csv("/content/drive/MyDrive/Data Science/telecom_churn_data.csv")

# Create new dataframe from previous one.
Tele_Churn = Tele_Churn_colab.copy(deep=True)

# To check all the variables label
Tele_Churn.head()

"""### Step 2: Inspecting the Dataframe   
Inspect the dataframe for dimensions, null-values, and summary of different numeric columns.
"""

# To Check the dimensions of the dataframe
Tele_Churn.shape

# To see the type of each column
Tele_Churn.info(verbose=True)

# To check the null values of each column
Tele_Churn.isnull().sum()

# Checking the percentage of missing values
round(100*(Tele_Churn.isnull().sum()/len(Tele_Churn.index)), 2)

# To check any duplicate value in various columns
Tele_Churn.duplicated().sum()

"""### Step 3: Data Cleaning"""

# To see the statistical aspects of the dataframe
Tele_Churn.describe()

# Few columns has '0' min. and max. therefore collect them in a variable and replace their 'NaN' value with Zero
col_val_0_all = ["loc_og_t2o_mou", "std_og_t2o_mou", "loc_ic_t2o_mou","std_ic_t2o_mou_6","std_ic_t2o_mou_7","std_ic_t2o_mou_8","std_ic_t2o_mou_9"]

# To replace respective columns 'NaN' value with '0'
Tele_Churn[col_val_0_all] = Tele_Churn[col_val_0_all].replace(np.NaN, 0)

# To get all the date columns which are mentioned as 'object' in our dataset
Tele_Churn_date = Tele_Churn.select_dtypes(include=['object'])

# To check all the variables label
Tele_Churn_date.head()

# Replace 'NaN' values of date columns related 'last_date_of_month' for (7,8,9) with their respective column value
Tele_Churn['last_date_of_month_7'] = Tele_Churn['last_date_of_month_7'].replace(np.NaN, '7/31/2014')
Tele_Churn['last_date_of_month_8'] = Tele_Churn['last_date_of_month_8'].replace(np.NaN, '8/31/2014')
Tele_Churn['last_date_of_month_9'] = Tele_Churn['last_date_of_month_9'].replace(np.NaN, '9/30/2014')

# To recheck Null values for concern column
Tele_Churn.last_date_of_month_7.isnull().sum()

# To recheck Null values for concern column
Tele_Churn.last_date_of_month_8.isnull().sum()

# To recheck Null values for concern column
Tele_Churn.last_date_of_month_9.isnull().sum()

"""#### Total Recharge data and the respective columns' status in a each month."""

# To check if 'total_rech_data' for a praticular month is Zero (0) then all other realted column's value will be respectively zero (0)
Rech_data_status_6 = Tele_Churn[["total_rech_data_6","date_of_last_rech_6","date_of_last_rech_data_6","max_rech_data_6","count_rech_2g_6","count_rech_3g_6","av_rech_amt_data_6"]]
Rech_data_status_7 = Tele_Churn[["total_rech_data_7","date_of_last_rech_7","date_of_last_rech_data_7","max_rech_data_7","count_rech_2g_7","count_rech_3g_7","av_rech_amt_data_7"]]
Rech_data_status_8 = Tele_Churn[["total_rech_data_8","date_of_last_rech_8","date_of_last_rech_data_8","max_rech_data_8","count_rech_2g_8","count_rech_3g_8","av_rech_amt_data_8"]]
Rech_data_status_9 = Tele_Churn[["total_rech_data_9","date_of_last_rech_9","date_of_last_rech_data_9","max_rech_data_9","count_rech_2g_9","count_rech_3g_9","av_rech_amt_data_9"]]

# To check columsn values
Rech_data_status_6.head(50)

# To check columsn values
Rech_data_status_7.head(100)

# To check columsn values
Rech_data_status_8.head(200)

# To check columan values
Rech_data_status_9.head(100)

"""### Inferences:
 - After observation of all the aobve table it is clear that wherever 'date_of_last_rech_ for 6,7,8,9 month has 'NaN' value then all other related columns also has no value, therefore we can either drop those Rows or replace with '0' as '0' also has no meaning.
 - From above tables it is clear that as and when Total_Rech_data has no value other related columns also has no value, therefore we can replace all 'NaN' values in the respective clumns with 'Zero' (0).

"""

# To collect all the columns in a variable 
Rech_data_status_all = ["total_rech_data_6","date_of_last_rech_6","date_of_last_rech_data_6","max_rech_data_6","count_rech_2g_6","count_rech_3g_6","av_rech_amt_data_6",
                        "total_rech_data_7","date_of_last_rech_7","date_of_last_rech_data_7","max_rech_data_7","count_rech_2g_7","count_rech_3g_7","av_rech_amt_data_7",
                        "total_rech_data_8","date_of_last_rech_8","date_of_last_rech_data_8","max_rech_data_8","count_rech_2g_8","count_rech_3g_8","av_rech_amt_data_8",
                        "total_rech_data_9","date_of_last_rech_9","date_of_last_rech_data_9","max_rech_data_9","count_rech_2g_9","count_rech_3g_9","av_rech_amt_data_9"]

# To replace respective columns 'NaN' value with '0'
Tele_Churn[Rech_data_status_all] = Tele_Churn[Rech_data_status_all].replace(np.NaN, 0)

# Checking the percentage of missing values
round(100*(Tele_Churn.isnull().sum()/len(Tele_Churn.index)), 2)

"""#### Convert above date columns data type from Object to Datetime."""

# To convert date column data type from object to datetime 
Tele_Churn[["last_date_of_month_6","last_date_of_month_7","last_date_of_month_8","last_date_of_month_9","date_of_last_rech_6","date_of_last_rech_7","date_of_last_rech_8","date_of_last_rech_9","date_of_last_rech_data_6","date_of_last_rech_data_7","date_of_last_rech_data_8","date_of_last_rech_data_9"]] = Tele_Churn[["last_date_of_month_6","last_date_of_month_7","last_date_of_month_8","last_date_of_month_9","date_of_last_rech_6","date_of_last_rech_7","date_of_last_rech_8","date_of_last_rech_9","date_of_last_rech_data_6","date_of_last_rech_data_7","date_of_last_rech_data_8","date_of_last_rech_data_9"]].apply(pd.to_datetime)

# To see the type of each column
Tele_Churn.info(verbose=True)

"""#### To check all incomings minutes of usage."""

# To check total incoming minutes of usage, if it is Zero (0) then other related column values will be also Zero (0)
All_icomings_6 = Tele_Churn[["total_ic_mou_6","loc_ic_mou_6","loc_ic_t2t_mou_6","loc_ic_t2m_mou_6","loc_ic_t2f_mou_6","std_ic_t2t_mou_6","std_ic_t2m_mou_6","std_ic_t2f_mou_6","std_ic_t2o_mou_6","std_ic_mou_6","spl_ic_mou_6","isd_ic_mou_6","ic_others_6","roam_ic_mou_6"]] 
All_icomings_7 = Tele_Churn[["total_ic_mou_7","loc_ic_mou_7","loc_ic_t2t_mou_7","loc_ic_t2m_mou_7","loc_ic_t2f_mou_7","std_ic_t2t_mou_7","std_ic_t2m_mou_7","std_ic_t2f_mou_7","std_ic_t2o_mou_7","std_ic_mou_7","spl_ic_mou_7","isd_ic_mou_7","ic_others_7","roam_ic_mou_7"]]
All_icomings_8 = Tele_Churn[["total_ic_mou_8","loc_ic_mou_8","loc_ic_t2t_mou_8","loc_ic_t2m_mou_8","loc_ic_t2f_mou_8","std_ic_t2t_mou_8","std_ic_t2m_mou_8","std_ic_t2f_mou_8","std_ic_t2o_mou_8","std_ic_mou_8","spl_ic_mou_8","isd_ic_mou_8","ic_others_8","roam_ic_mou_8"]] 
All_icomings_9 = Tele_Churn[["total_ic_mou_9","loc_ic_mou_9","loc_ic_t2t_mou_9","loc_ic_t2m_mou_9","loc_ic_t2f_mou_9","std_ic_t2t_mou_9","std_ic_t2m_mou_9","std_ic_t2f_mou_9","std_ic_t2o_mou_9","std_ic_mou_9","spl_ic_mou_9","isd_ic_mou_9","ic_others_9","roam_ic_mou_9"]]

# To check columan values
All_icomings_6.head(10)

# To check columan values
All_icomings_7.head(10)

# To check columan values
All_icomings_8.head(10)

# To check columan values
All_icomings_9.head(10)

"""### Inferences
- From all of the above columns it is clear that as and when "Total_ic_mou" is '0' all the incoming columns has 'NaN' value therfore we can replace all such "NaN" with "Zero" only

"""

# To collect all the columns in a variable 
Incomg_data_status_all = ["loc_ic_mou_6","loc_ic_t2t_mou_6","loc_ic_t2m_mou_6","loc_ic_t2f_mou_6","std_ic_t2t_mou_6","std_ic_t2m_mou_6","std_ic_t2f_mou_6","std_ic_mou_6","spl_ic_mou_6","isd_ic_mou_6","ic_others_6","roam_ic_mou_6",
                          "loc_ic_mou_7","loc_ic_t2t_mou_7","loc_ic_t2m_mou_7","loc_ic_t2f_mou_7","std_ic_t2t_mou_7","std_ic_t2m_mou_7","std_ic_t2f_mou_7","std_ic_mou_7","spl_ic_mou_7","isd_ic_mou_7","ic_others_7","roam_ic_mou_7",
                          "loc_ic_mou_8","loc_ic_t2t_mou_8","loc_ic_t2m_mou_8","loc_ic_t2f_mou_8","std_ic_t2t_mou_8","std_ic_t2m_mou_8","std_ic_t2f_mou_8","std_ic_mou_8","spl_ic_mou_8","isd_ic_mou_8","ic_others_8","roam_ic_mou_8", 
                          "loc_ic_mou_9","loc_ic_t2t_mou_9","loc_ic_t2m_mou_9","loc_ic_t2f_mou_9","std_ic_t2t_mou_9","std_ic_t2m_mou_9","std_ic_t2f_mou_9","std_ic_mou_9","spl_ic_mou_9","isd_ic_mou_9","ic_others_9","roam_ic_mou_9"]

# To replace respective columns 'NaN' value with '0'
Tele_Churn[Incomg_data_status_all] = Tele_Churn[Incomg_data_status_all].replace(np.NaN, 0)

# Checking the percentage of missing values
round(100*(Tele_Churn.isnull().sum()/len(Tele_Churn.index)), 2)

"""#### To check all outgoings and do imputation accordingly."""

# To check total outgoing minutes of usage, if it is Zero (0) then other related column values may be also Zero (0)
All_otg_6 = Tele_Churn[["total_og_mou_6","onnet_mou_6", "offnet_mou_6", "roam_og_mou_6", "loc_og_t2t_mou_6", "loc_og_t2m_mou_6", "loc_og_t2f_mou_6", "loc_og_t2c_mou_6", "loc_og_mou_6", "std_og_t2t_mou_6", "std_og_t2m_mou_6", "std_og_t2f_mou_6", "std_og_t2c_mou_6", "std_og_mou_6", "isd_og_mou_6", "spl_og_mou_6", "og_others_6"]] 
All_otg_7 = Tele_Churn[["total_og_mou_7","onnet_mou_7", "offnet_mou_7", "roam_og_mou_7", "loc_og_t2t_mou_7", "loc_og_t2m_mou_7", "loc_og_t2f_mou_7", "loc_og_t2c_mou_7", "loc_og_mou_7", "std_og_t2t_mou_7", "std_og_t2m_mou_7", "std_og_t2f_mou_7", "std_og_t2c_mou_7", "std_og_mou_7", "isd_og_mou_7", "spl_og_mou_7", "og_others_7"]]
All_otg_8 = Tele_Churn[["total_og_mou_8","onnet_mou_8", "offnet_mou_8", "roam_og_mou_8", "loc_og_t2t_mou_8", "loc_og_t2m_mou_8", "loc_og_t2f_mou_8", "loc_og_t2c_mou_8", "loc_og_mou_8", "std_og_t2t_mou_8", "std_og_t2m_mou_8", "std_og_t2f_mou_8", "std_og_t2c_mou_8", "std_og_mou_8", "isd_og_mou_8", "spl_og_mou_8", "og_others_8"]] 
All_otg_9 = Tele_Churn[["total_og_mou_9","onnet_mou_9", "offnet_mou_9", "roam_og_mou_9", "loc_og_t2t_mou_9", "loc_og_t2m_mou_9", "loc_og_t2f_mou_9", "loc_og_t2c_mou_9", "loc_og_mou_9", "std_og_t2t_mou_9", "std_og_t2m_mou_9", "std_og_t2f_mou_9", "std_og_t2c_mou_9", "std_og_mou_9", "isd_og_mou_9", "spl_og_mou_9", "og_others_9"]]

# To check columan values
All_otg_6.head(10)

# To check columan values
All_otg_7.head(10)

# To check columan values
All_otg_8.head(10)

# To check columan values
All_otg_9.head(10)

"""### Inferences
- From all of the above columns it is clear that as and when "Total_og_mou" is '0' all the outgoing columns has 'NaN' value therfore we can replace all such "NaN" with "Zero" only

"""

# To collect all the columns in a variable 
Otg_mou_status_all = ["onnet_mou_6", "offnet_mou_6", "roam_og_mou_6", "loc_og_t2t_mou_6", "loc_og_t2m_mou_6", "loc_og_t2f_mou_6", "loc_og_t2c_mou_6", "loc_og_mou_6", "std_og_t2t_mou_6", "std_og_t2m_mou_6", "std_og_t2f_mou_6", "std_og_t2c_mou_6", "std_og_mou_6", "isd_og_mou_6", "spl_og_mou_6", "og_others_6",
                      "onnet_mou_7", "offnet_mou_7", "roam_og_mou_7", "loc_og_t2t_mou_7", "loc_og_t2m_mou_7", "loc_og_t2f_mou_7", "loc_og_t2c_mou_7", "loc_og_mou_7", "std_og_t2t_mou_7", "std_og_t2m_mou_7", "std_og_t2f_mou_7", "std_og_t2c_mou_7", "std_og_mou_7", "isd_og_mou_7", "spl_og_mou_7", "og_others_7",
                      "onnet_mou_8", "offnet_mou_8", "roam_og_mou_8", "loc_og_t2t_mou_8", "loc_og_t2m_mou_8", "loc_og_t2f_mou_8", "loc_og_t2c_mou_8", "loc_og_mou_8", "std_og_t2t_mou_8", "std_og_t2m_mou_8", "std_og_t2f_mou_8", "std_og_t2c_mou_8", "std_og_mou_8", "isd_og_mou_8", "spl_og_mou_8", "og_others_8", 
                      "onnet_mou_9", "offnet_mou_9", "roam_og_mou_9", "loc_og_t2t_mou_9", "loc_og_t2m_mou_9", "loc_og_t2f_mou_9", "loc_og_t2c_mou_9", "loc_og_mou_9", "std_og_t2t_mou_9", "std_og_t2m_mou_9", "std_og_t2f_mou_9", "std_og_t2c_mou_9", "std_og_mou_9", "isd_og_mou_9", "spl_og_mou_9", "og_others_9"]

# To replace respective columns 'NaN' value with '0'
Tele_Churn[Otg_mou_status_all] = Tele_Churn[Otg_mou_status_all].replace(np.NaN, 0)

# Checking the percentage of missing values
round(100*(Tele_Churn.isnull().sum()/len(Tele_Churn.index)), 2)

"""### Inferences
 - To check column variables which has Zero variance.
"""

# To check variance in columns
print(Tele_Churn.var())

# To drop various columns which has Zero variance 
Tele_Churn.drop(['circle_id','loc_og_t2o_mou','std_og_t2o_mou','loc_ic_t2o_mou','std_og_t2c_mou_6','std_og_t2c_mou_7','std_og_t2c_mou_8',
                 'std_ic_t2o_mou_6','std_ic_t2o_mou_7','std_ic_t2o_mou_8','std_og_t2c_mou_9'], axis=1, inplace=True)

# To check variance in columns
print(Tele_Churn.var())

# Checking the percentage of missing values
Tele_Churn_null_per = round(100*(Tele_Churn.isnull().sum()/len(Tele_Churn.index)), 2)
Tele_Churn_null_per

"""### Inferences
 - To check number of columns still having more than 40% NaN values and not much useful.
"""

# To check number of columns which has Null values greater than 40%
len(Tele_Churn_null_per[Tele_Churn_null_per.values>=(40)])

# List all the columns which values is greater than and equal to 40%
Tele_Churn_null_per_40 = list(Tele_Churn_null_per[Tele_Churn_null_per.values>=40].index)
Tele_Churn_null_per_40

# Drop all the values which values is greater than equal to 40%.
Tele_Churn_not_null = Tele_Churn.drop(labels = Tele_Churn_null_per_40, axis=1, inplace=True)

# Checking the percentage of missing values
round(100*(Tele_Churn.isnull().sum()/len(Tele_Churn.index)), 2)

# To see the type of each column
Tele_Churn.info(verbose=True)

# To Check the dimensions of the dataframe
Tele_Churn.shape

# To check all the variables label
Tele_Churn.head()

"""##### Filter the data in terms of Average recharge done by each user in the month of June, July (Good Phase) to define High value users.

"""

# To calculate Total data recharge amount per user in 'June' and 'July'.
Tele_Churn["Total_data_rech_amt_6"] = Tele_Churn["total_rech_data_6"] * Tele_Churn["av_rech_amt_data_6"]
Tele_Churn["Total_data_rech_amt_7"] = Tele_Churn["total_rech_data_7"] * Tele_Churn["av_rech_amt_data_7"]
Tele_Churn["Total_data_rech_amt_8"] = Tele_Churn["total_rech_data_8"] * Tele_Churn["av_rech_amt_data_8"]

# To calculate Net data recharge amount per user for the month of 'June' and 'July'.
Tele_Churn["Net_data_rechrg_amt_6"] = Tele_Churn["total_rech_amt_6"] + Tele_Churn["Total_data_rech_amt_6"] 
Tele_Churn["Net_data_rechrg_amt_7"] = Tele_Churn["total_rech_amt_7"] + Tele_Churn["Total_data_rech_amt_7"] 
Tele_Churn["Net_data_rechrg_amt_8"] = Tele_Churn["total_rech_amt_8"] + Tele_Churn["Total_data_rech_amt_8"]

# To check all the variables label
Tele_Churn.head()

# To calculate Average recharge amount per user for the month of 'June' and 'July'.
Tele_Churn["Avrg_rchg_Amt_Good_Phase"] = (Tele_Churn["Net_data_rechrg_amt_6"] + Tele_Churn["Net_data_rechrg_amt_7"])/2

# To check all the variables label
Tele_Churn.head()

# To find the 80% in total revenue to differentiate the High Value users based on revenue as the first two months are the ‘Good’ phase
High_value_user = round(Tele_Churn["Avrg_rchg_Amt_Good_Phase"].quantile(0.80))
High_value_user

# Filter the data for top 20% mentioned as High Value Users
Tele_Churn = Tele_Churn[Tele_Churn["Avrg_rchg_Amt_Good_Phase"]>=High_value_user]

# To check all the variables label
Tele_Churn.head(10).sort_values(by = "Avrg_rchg_Amt_Good_Phase", ascending = False)

# To Check the dimensions of the dataframe
Tele_Churn.shape

"""##### Now there are total 20031 users which are considerd as High value users."""

# Checking the percentage of missing values
round(100*(Tele_Churn.isnull().sum()/len(Tele_Churn.index)), 2)

# To see the type of each column
Tele_Churn.info(verbose=True)

"""#### To find out total usage to calculate 'Churn' as in this project 'Churn' is based on usage"""

# To find overall usage of data and calls
Tele_Churn['Overall_Usage'] = Tele_Churn['total_og_mou_9'] + Tele_Churn['total_ic_mou_9'] + Tele_Churn['vol_2g_mb_9'] + Tele_Churn['vol_3g_mb_9']

# To check all the variables label
Tele_Churn.head(10).sort_values(by = 'Overall_Usage', ascending = False)

# To find 'Churn' based on overall usage, whereas churn - 1, not churn - 0
Tele_Churn['churn'] = Tele_Churn['Overall_Usage'].apply(lambda x: 1 if x == 0 else 0)

# To check all the variables label
Tele_Churn.head(30)

# To calculate % of Churn and Not-Churn
churn_per = round(100*(Tele_Churn['churn'].value_counts()/len(Tele_Churn.index)),2)
churn_per

"""- As per the above results maximum users are not churned (92.09%) and only 7.91% users are churned, therefore there would be a class imbalance which can be managed."""

# Churn rate
churn_col = Tele_Churn['churn']
churn_rate = round(((sum(churn_col)/len(churn_col.index))*100),2)
churn_rate

"""#### Need to drop columns which are already used to calculate overall usage based on 9th month"""

# To drop various unnecessary columns which not much useful or used already to create usage based churn 
Tele_Churn.drop(['total_og_mou_9','total_ic_mou_9','vol_2g_mb_9','vol_3g_mb_9'], axis=1, inplace=True)

"""#### Remove all the other variables which are related to 9 month as now we have 'churn' variable"""

churn_colms = [col for col in Tele_Churn.columns if '_9' in col]
churn_colms

# To get the length of the cols related to 9th month or churn month
len(churn_colms)

# To drop various unnecessary columns which are related to 9th month 
Tele_Churn.drop(churn_colms, axis=1, inplace=True)

# To drop unnecessary column related to 9th month (Sept.) 
Tele_Churn.drop(["sep_vbc_3g"], axis=1, inplace=True)

# To Check the dimensions of the dataframe
Tele_Churn.shape

# To check all the variables label
Tele_Churn.head()

"""#### Seperate Churned and Not Churned users and check the ratio """

# To check whether how many are the Non-churned users 
not_churn_users = Tele_Churn[Tele_Churn.churn == 0]
not_churn_users.head()

# To check the sahpe of the dataframe
not_churn_users.shape

# To check whether how many are the churned users 
churn_users = Tele_Churn[Tele_Churn.churn == 1]
churn_users.head()

# To check the sahpe of the dataframe
churn_users.shape

# To check the % of Data that has Churned users (Values = 1):
Churn_Per = round(((sum(Tele_Churn.churn == 1)/len(Tele_Churn['churn'].index))*100),2)
Churn_Per

# To check the % of Data that has Not_churned users (Values = 0):
Not_Churn_Per = round(((sum(Tele_Churn.churn == 0)/len(Tele_Churn['churn'].index))*100),2)
Not_Churn_Per

"""#### Inferences
- 18446 are not churned users whereas 1585 are churned users.
- Overall Churn users are 7.91% only.
- Whereas, Not-Churn users are 92.09%.
- As Not-Churn % is very high (>90%) w.r.t. Churn users we can say that there is a very high imbalance between these 2 categories.
"""

# To Check the dimensions of the dataframe
Tele_Churn.shape

# To check columan values
Tele_Churn.head()

"""#### To get some new column from dates and drop useless columns related to dates.

"""

# To calculate no. of days in month before person is recharging 
Tele_Churn["t_days_rechrg_before_EOM_6"] = Tele_Churn["last_date_of_month_6"] - Tele_Churn["date_of_last_rech_6"]
Tele_Churn["t_days_rechrg_before_EOM_7"] = Tele_Churn["last_date_of_month_7"] - Tele_Churn["date_of_last_rech_7"]
Tele_Churn["t_days_rechrg_before_EOM_8"] = Tele_Churn["last_date_of_month_8"] - Tele_Churn["date_of_last_rech_8"]

# To drop various date columns
Tele_Churn.drop(['last_date_of_month_6','last_date_of_month_7','last_date_of_month_8','date_of_last_rech_6','date_of_last_rech_7',
                 'date_of_last_rech_8','date_of_last_rech_data_6','date_of_last_rech_data_7','date_of_last_rech_data_8'], axis=1, inplace=True)

# To Check the dimensions of the dataframe
Tele_Churn.shape

# To check columan values
Tele_Churn.head()

# To see the type of each column
Tele_Churn.info(verbose=True)

# To no. of dyas from datetime datatype of few date variables
Tele_Churn["t_days_rechrg_before_EOM_6"] = Tele_Churn["t_days_rechrg_before_EOM_6"].dt.days
Tele_Churn["t_days_rechrg_before_EOM_7"] = Tele_Churn["t_days_rechrg_before_EOM_7"].dt.days
Tele_Churn["t_days_rechrg_before_EOM_8"] = Tele_Churn["t_days_rechrg_before_EOM_8"].dt.days

# To see the type of each column
Tele_Churn.info(verbose=True)

# To check columan values
Tele_Churn.head()

# To calculate Average revenue per user for the month of 'June' and 'July'.
Tele_Churn["arpu_6_7"] = round((Tele_Churn["arpu_6"] + Tele_Churn["arpu_7"]).mean(),2)

# To drop variables which were used to calculate Average Revenue Per User
Tele_Churn.drop(['arpu_6','arpu_7'], axis=1, inplace=True)

# To Check the dimensions of the dataframe
Tele_Churn.shape

# To check columan values
Tele_Churn.head()

# To Check the dimensions of the dataframe
Tele_Churn.shape

# To derive one more new variable with respect to 'aon'(Age on Network), 
Tele_Churn['Age_on_N/W'] = round((Tele_Churn['aon']/30), 0)

# To drop variables which were used to calculate Age on Network
Tele_Churn.drop(["aon"], axis=1, inplace=True)

# To Check the dimensions of the dataframe
Tele_Churn.shape

# To check columan values
Tele_Churn.head()

# Drop few more columns which are not much useful as we have used before to calculate Net data recharge 
Tele_Churn.drop(["max_rech_data_6", "max_rech_data_7","max_rech_data_8","max_rech_amt_6","max_rech_amt_7","max_rech_amt_8",
                 "total_rech_data_6","total_rech_data_7","total_rech_data_8","av_rech_amt_data_6","av_rech_amt_data_7","av_rech_amt_data_8",
                 "total_rech_num_6","total_rech_num_7","total_rech_num_8","count_rech_3g_6","count_rech_3g_7","count_rech_3g_8"], axis=1, inplace=True)

# "total_rech_amt_6","total_rech_amt_7","total_rech_amt_8","Total_data_rech_amt_6","Total_data_rech_amt_7","Total_data_rech_amt_8"

# To Check the dimensions of the dataframe
Tele_Churn.shape

# To check columan values
Tele_Churn.head()

# To collect sum of all local outgoing minutes of usage in a single variable
Tele_Churn["Total_local_og_6"] = round(Tele_Churn[["loc_og_t2t_mou_6", "loc_og_t2m_mou_6", "loc_og_t2f_mou_6","loc_og_t2c_mou_6","loc_og_mou_6"]].sum(axis=1),2)
Tele_Churn["Total_local_og_7"] = round(Tele_Churn[["loc_og_t2t_mou_7", "loc_og_t2m_mou_7", "loc_og_t2f_mou_7","loc_og_t2c_mou_7","loc_og_mou_7"]].sum(axis=1),2)
Tele_Churn["Total_local_og_8"] = round(Tele_Churn[["loc_og_t2t_mou_8", "loc_og_t2m_mou_8", "loc_og_t2f_mou_8","loc_og_t2c_mou_8","loc_og_mou_8"]].sum(axis=1),2)

# To collect sum of all local incoming minutes of usage in a single variable
Tele_Churn["Total_local_ic_6"] = round(Tele_Churn[["loc_ic_t2t_mou_6", "loc_ic_t2m_mou_6", "loc_ic_t2f_mou_6","loc_ic_mou_6"]].sum(axis=1),2)
Tele_Churn["Total_local_ic_7"] = round(Tele_Churn[["loc_ic_t2t_mou_7", "loc_ic_t2m_mou_7", "loc_ic_t2f_mou_7","loc_ic_mou_7"]].sum(axis=1),2)
Tele_Churn["Total_local_ic_8"] = round(Tele_Churn[["loc_ic_t2t_mou_8", "loc_ic_t2m_mou_8", "loc_ic_t2f_mou_8","loc_ic_mou_8"]].sum(axis=1),2)

# To collect sum of all std incoming minutes of usage in a single variable
Tele_Churn["Total_std_ic_6"] = round(Tele_Churn[["std_ic_t2t_mou_6", "std_ic_t2m_mou_6", "std_ic_t2f_mou_6","std_ic_mou_6"]].sum(axis=1),2)
Tele_Churn["Total_std_ic_7"] = round(Tele_Churn[["std_ic_t2t_mou_7", "std_ic_t2m_mou_7", "std_ic_t2f_mou_7","std_ic_mou_7"]].sum(axis=1),2)
Tele_Churn["Total_std_ic_8"] = round(Tele_Churn[["std_ic_t2t_mou_8", "std_ic_t2m_mou_8", "std_ic_t2f_mou_8","std_ic_mou_8"]].sum(axis=1),2)

# To collect sum of all std outing minutes of usage in a single variable
Tele_Churn["Total_std_og_6"] = round(Tele_Churn[["std_og_t2t_mou_6", "std_og_t2m_mou_6", "std_og_t2f_mou_6", "std_og_mou_6"]].sum(axis=1),2)
Tele_Churn["Total_std_og_7"] = round(Tele_Churn[["std_og_t2t_mou_7", "std_og_t2m_mou_7", "std_og_t2f_mou_7", "std_og_mou_7"]].sum(axis=1),2)
Tele_Churn["Total_std_og_8"] = round(Tele_Churn[["std_og_t2t_mou_8", "std_og_t2m_mou_8", "std_og_t2f_mou_8", "std_og_mou_8"]].sum(axis=1),2)

# To collect sum of all isd,spl and other incoming minutes of usage in a single variable
Tele_Churn["Total_othrs_ic_6"] = round(Tele_Churn[["spl_ic_mou_6", "isd_ic_mou_6", "ic_others_6"]].sum(axis=1),2)
Tele_Churn["Total_othrs_ic_7"] = round(Tele_Churn[["spl_ic_mou_7", "isd_ic_mou_7", "ic_others_7"]].sum(axis=1),2)
Tele_Churn["Total_othrs_ic_8"] = round(Tele_Churn[["spl_ic_mou_8", "isd_ic_mou_8", "ic_others_8"]].sum(axis=1),2)

# To collect sum of all isd,spl and other outing minutes of usage in a single variable
Tele_Churn["Total_othrs_og_6"] = round(Tele_Churn[["spl_og_mou_6", "isd_og_mou_6", "og_others_6"]].sum(axis=1),2)
Tele_Churn["Total_othrs_og_7"] = round(Tele_Churn[["spl_og_mou_7", "isd_og_mou_7", "og_others_7"]].sum(axis=1),2)
Tele_Churn["Total_othrs_og_8"] = round(Tele_Churn[["spl_og_mou_8", "isd_og_mou_8", "og_others_8"]].sum(axis=1),2)

# Drop few more columns which are not much useful as we have used before to calculate all incoming and outgoing minutes of usages 
Tele_Churn.drop(["loc_og_t2t_mou_6", "loc_og_t2m_mou_6", "loc_og_t2f_mou_6","loc_og_t2c_mou_6","loc_og_mou_6", "loc_og_t2t_mou_7", 
                 "loc_og_t2m_mou_7", "loc_og_t2f_mou_7","loc_og_t2c_mou_7","loc_og_mou_7", "loc_og_t2t_mou_8", "loc_og_t2m_mou_8", 
                 "loc_og_t2f_mou_8","loc_og_t2c_mou_8","loc_og_mou_8", "loc_ic_t2t_mou_6", "loc_ic_t2m_mou_6", "loc_ic_t2f_mou_6", 
                 "loc_ic_mou_6", "loc_ic_t2t_mou_7", "loc_ic_t2m_mou_7", "loc_ic_t2f_mou_7","loc_ic_mou_7", "loc_ic_t2t_mou_8", 
                 "loc_ic_t2m_mou_8", "loc_ic_t2f_mou_8","loc_ic_mou_8", "std_ic_t2t_mou_6", "std_ic_t2m_mou_6", "std_ic_t2f_mou_6",
                "std_ic_mou_6", "std_ic_t2t_mou_7", "std_ic_t2m_mou_7", "std_ic_t2f_mou_7","std_ic_mou_7","std_ic_t2t_mou_8", 
                 "std_ic_t2m_mou_8", "std_ic_t2f_mou_8","std_ic_mou_8", "std_og_t2t_mou_6", "std_og_t2m_mou_6", "std_og_t2f_mou_6", 
                 "std_og_mou_6","std_og_t2t_mou_7", "std_og_t2m_mou_7", "std_og_t2f_mou_7", "std_og_mou_7","std_og_t2t_mou_8", 
                 "std_og_t2m_mou_8", "std_og_t2f_mou_8", "std_og_mou_8", "spl_ic_mou_6", "isd_ic_mou_6", "ic_others_6","spl_ic_mou_7", 
                 "isd_ic_mou_7", "ic_others_7", "spl_ic_mou_8", "isd_ic_mou_8", "ic_others_8", "spl_og_mou_6", "isd_og_mou_6", 
                 "og_others_6","spl_og_mou_7", "isd_og_mou_7", "og_others_7","spl_og_mou_8", "isd_og_mou_8", "og_others_8"], 
                  axis=1, inplace=True)

# To Check the dimensions of the dataframe
Tele_Churn.shape

# To check columan values
Tele_Churn.head()

# To collect sum of all roaming minutes of usage in a single variable
Tele_Churn["Total_roam_6"] = round(Tele_Churn[["roam_ic_mou_6", "roam_og_mou_6"]].sum(axis=1),2)
Tele_Churn["Total_roam_7"] = round(Tele_Churn[["roam_ic_mou_7", "roam_og_mou_7"]].sum(axis=1),2)
Tele_Churn["Total_roam_8"] = round(Tele_Churn[["roam_ic_mou_8", "roam_og_mou_8"]].sum(axis=1),2)

# Drop few more columns which are not much useful as we have used before to calculate all incoming and outgoing roaming minutes of usages 
Tele_Churn.drop(["roam_ic_mou_6", "roam_og_mou_6","roam_ic_mou_7", "roam_og_mou_7","roam_ic_mou_8", "roam_og_mou_8"], axis=1, inplace=True)

# To Check the dimensions of the dataframe
Tele_Churn.shape

# To check columan values
Tele_Churn.head()

# To collect sum of all 2g, 3g used data in a single variable
Tele_Churn["Total_data_2g_3g_6"] = round(Tele_Churn[["vol_2g_mb_6", "vol_3g_mb_6", "jun_vbc_3g"]].sum(axis=1),2)
Tele_Churn["Total_data_2g_3g_7"] = round(Tele_Churn[["vol_2g_mb_7", "vol_3g_mb_7", "jul_vbc_3g"]].sum(axis=1),2)
Tele_Churn["Total_data_2g_3g_8"] = round(Tele_Churn[["vol_2g_mb_8", "vol_3g_mb_8", "aug_vbc_3g"]].sum(axis=1),2)

# Drop few more columns which are not much useful as we have used before to calculate all 2g, 3g data usged 
Tele_Churn.drop(["vol_2g_mb_6", "vol_3g_mb_6", "jun_vbc_3g","vol_2g_mb_7", "vol_3g_mb_7", "jul_vbc_3g","vol_2g_mb_8", "vol_3g_mb_8", 
                 "aug_vbc_3g"], axis=1, inplace=True)

# To Check the dimensions of the dataframe
Tele_Churn.shape

# To drop few more variables which are still not much useful
Tele_Churn.drop(["count_rech_2g_6", "count_rech_2g_7", "count_rech_2g_8", "onnet_mou_6",	"onnet_mou_7","onnet_mou_8","offnet_mou_6",	"offnet_mou_7",	"offnet_mou_8"], axis=1, inplace=True)

# To Check the dimensions of the dataframe
Tele_Churn.shape

# To check columan values
Tele_Churn.head()

"""#### To check Coorelation between various variables."""

# To recheck the correlation coefficients to know which variables are highly correlated
Tele_Churn_cor = Tele_Churn.corr()

# To plot the Heatmap for all the varaibles 
fig = plt.figure(figsize = (35, 30))
sns.heatmap(Tele_Churn_cor, cmap="RdYlGn", annot = True )
plt.title("Correlation between various numercial varibales\n", fontdict={'fontsize':30,'fontweight':5,'color':'Green'})
plt.xlabel("\nNumerical Variables",fontdict={'fontsize':25,'fontweight':8,'color':'Brown'})
plt.ylabel("\nNumerical Variables\n",fontdict={'fontsize':25,'fontweight':8,'color':'Brown'})
plt.show()

# To collect and see absolute coorelation matrix
Tele_churn_matrix = Tele_Churn.corr().abs()
Tele_churn_matrix

# To find out Upper Trainangle
Tele_upper_tri = Tele_churn_matrix.where(np.triu(np.ones(Tele_churn_matrix.shape), k=1).astype(np.bool))
Tele_upper_tri

# To find out the features which are highly correlated
Tele_Churn_drop_90 = [column for column in Tele_upper_tri.columns if any(Tele_upper_tri[column] > 0.90)]
Tele_Churn_drop_90

# To drop the variables which are highly correlated. (>90%)
Tele_Churn.drop(['total_rech_amt_8', 'Net_data_rechrg_amt_6', 'Net_data_rechrg_amt_7', 'Net_data_rechrg_amt_8'], axis=1, inplace=True)

# To recheck the correlation coefficients to know which variables are highly correlated
Tele_Churn_cor_2 = Tele_Churn.corr()

# To plot the Heatmap for all the varaibles 
fig = plt.figure(figsize = (35, 30))
sns.heatmap(Tele_Churn_cor_2, cmap="RdYlGn", annot = True )
plt.title("Correlation between various numercial varibales\n", fontdict={'fontsize':30,'fontweight':5,'color':'Green'})
plt.xlabel("\nNumerical Variables",fontdict={'fontsize':25,'fontweight':8,'color':'Brown'})
plt.ylabel("\nNumerical Variables\n",fontdict={'fontsize':25,'fontweight':8,'color':'Brown'})
plt.show()

# To Check the dimensions of the dataframe
Tele_Churn.shape

"""#### Outlier Treatment"""

# To check all the variables label
Tele_Churn.head()

# To check the sahpe of the dataframe
Tele_Churn.shape

# To see the statistical aspects of the dataframe
round(Tele_Churn.describe(percentiles = [0, 0.25, 0.5, 0.75, 0.80, 0.85, 0.90, 0.95, 0.99]), 2)

"""### Inferences:
- As per the above details it is clear that there are outliers in the dataframe, which are required to remove.
"""

churn_cols = [x for x in Tele_Churn.columns if x not in ['mobile_number','churn']]

for x in churn_cols:
    Percent = Tele_Churn[x].quantile([0.01,0.95]).values
    Tele_Churn[x][Tele_Churn[x] <= Percent[0]] = Percent[0]
    Tele_Churn[x][Tele_Churn[x] >= Percent[1]] = Percent[1]

# To see the statistical aspects of the dataframe
round(Tele_Churn.describe(percentiles = [0, 0.25, 0.5, 0.75, 0.80, 0.85, 0.90, 0.95, 0.99]), 2)

# To check the sahpe of the dataframe
Tele_Churn.shape

# To check all the variables label
Tele_Churn.head()

# Checking the percentage of missing values
round(100*(Tele_Churn.isnull().sum()/len(Tele_Churn.index)), 2)

"""## EDA

### A) Univeriate Analysis
"""

# To analyze Telecomm Users (Churn and Not_Churned) ('1' = Churn, '0'= Not_Churn)
fig = plt.figure(figsize=(6,5))
Tele_Churn['churn'].value_counts().plot.barh()
plt.title("Churn Vs Count\n", fontdict={'fontsize':20,'fontweight':5,'color':'Green'})
plt.xlabel("\nCounts\n",fontdict={'fontsize':15,'fontweight':5,'color':'Brown'})
plt.ylabel("Churn Users Difference\n",fontdict={'fontsize':15,'fontweight':5,'color':'Brown'})
plt.show()

"""#### Inferences:
- Above graph represents that Not-Churn users are more than the Churn users among high value users. Therefore there is no much issue for the company in terms of revenue.

### Bivariate/Multivariate Analysis.
"""

# To analyze Month wise Average Revenue Per User 
arp = Tele_Churn.groupby(['churn'])['arpu_6_7', 'arpu_8'].mean()
arp.plot.barh()    
plt.title("Month wise Avg. Revenue per user\n", fontdict={'fontsize':15,'fontweight':5,'color':'Green'})
plt.xlabel("\nCount\n",fontdict={'fontsize':15,'fontweight':5,'color':'Brown'})
plt.ylabel("Churn\n",fontdict={'fontsize':15,'fontweight':5,'color':'Brown'})
plt.show()

"""#### Inferences: 
- As per the above graph Average Revenue Per Churned users has been decreased from June_July to August. and which is minimum in the moth of August.
- Therefore as overall revenue of that user decreases then try to give various offers as per the requirement and try to retain that customer.
"""

# To analyze Month wise local outgoing 
tl_og = Tele_Churn.groupby(['churn'])['Total_local_og_6', 'Total_local_og_7', 'Total_local_og_8'].mean()
tl_og.plot.barh()    
plt.title("Month wise Total local outgoing\n", fontdict={'fontsize':15,'fontweight':5,'color':'Green'})
plt.xlabel("\nCount\n",fontdict={'fontsize':15,'fontweight':5,'color':'Brown'})
plt.ylabel("Churn\n",fontdict={'fontsize':15,'fontweight':5,'color':'Brown'})
plt.show()

"""
#### Inferences:
- As per the above graph it is clear that Total Local outgoing for 'Churn' users has been decreased from June to August. Therfore company need to obseve this particular parameter."""

# To analyze Month wise std outgoing 
std_og = Tele_Churn.groupby(['churn'])['Total_std_og_6', 'Total_std_og_7', 'Total_std_og_8'].mean()
std_og.plot.barh()    
plt.title("Month wise Total STD outgoing\n", fontdict={'fontsize':15,'fontweight':5,'color':'Green'})
plt.xlabel("\nCount\n",fontdict={'fontsize':15,'fontweight':5,'color':'Brown'})
plt.ylabel("Churn\n",fontdict={'fontsize':15,'fontweight':5,'color':'Brown'})
plt.show()

"""
#### Inferences:
- As per the above graph it is clear that Total STD outgoing for 'Churn' users has been decreased from June to August. In the month of August it is very low than Non-Churn users. Whereas for Non-Churn it is not that much low."""

# To analyze Month wise no. of days whenn customer recharge before EOM 
days_EOM = Tele_Churn.groupby(['churn'])['t_days_rechrg_before_EOM_6', 't_days_rechrg_before_EOM_7', 't_days_rechrg_before_EOM_8'].mean()
days_EOM.plot.barh()    
plt.title("Month wise Total days to recharge before EOM\n", fontdict={'fontsize':15,'fontweight':5,'color':'Green'})
plt.xlabel("\nNo. of days\n",fontdict={'fontsize':15,'fontweight':5,'color':'Brown'})
plt.ylabel("Churn\n",fontdict={'fontsize':15,'fontweight':5,'color':'Brown'})
plt.show()

"""#### Inferences:
- As per the above graph it is clear that users who are Churned are recharding very late in the month of August. Means days difference is more than June and July. Whereas for the Non-Churned users gap of no. of days is less for recharging their no.

"""

# To analyze Month wise Total Data Recharge Amount 
data_amt = Tele_Churn.groupby(['churn'])['Total_data_rech_amt_6', 'Total_data_rech_amt_7', 'Total_data_rech_amt_8'].mean()
data_amt.plot.barh()    
plt.title("Month wise Total data recharge Amount\n", fontdict={'fontsize':15,'fontweight':5,'color':'Green'})
plt.xlabel("\nAmount\n",fontdict={'fontsize':15,'fontweight':5,'color':'Brown'})
plt.ylabel("Churn\n",fontdict={'fontsize':15,'fontweight':5,'color':'Brown'})
plt.show()

"""#### Inferences:
- As per the above graph it is clear that for Churned users 'Total Data Recharge Amount' is very less in the month of August and it is in  decreasing order with respect to June and July. Whereas, for Non-Churned users this amount is almost similar as in June.
  Therefore company need to closely observe this particualr variable.

"""

# To analyze Month wise Total incoming, outgoing Roaming data 
tl_og_r = Tele_Churn.groupby(['churn'])['Total_roam_6', 'Total_roam_7', 'Total_roam_8'].mean()
tl_og_r.plot.barh()    
plt.title("Month wise Total Incmoing and Outgoing Roaming\n", fontdict={'fontsize':15,'fontweight':5,'color':'Green'})
plt.xlabel("\nCount\n",fontdict={'fontsize':15,'fontweight':5,'color':'Brown'})
plt.ylabel("Churn\n",fontdict={'fontsize':15,'fontweight':5,'color':'Brown'})
plt.show()

"""#### It is stated from the above graph that Total Roaming data still in decreasin gorder from June to August for Churned users but the total Roaming value is higher fro Churned users than Non-Churned users."""

# TO check the columns of the dataframe
Tele_Churn.columns

# To analyze Month wise Total 2g, 3g Data 
tl_2g_3g = Tele_Churn.groupby(['churn'])['Total_data_2g_3g_6', 'Total_data_2g_3g_7', 'Total_data_2g_3g_8'].mean()
tl_2g_3g.plot.barh()    
plt.title("Month wise Total Data Recharge\n", fontdict={'fontsize':15,'fontweight':5,'color':'Green'})
plt.xlabel("\nCount\n",fontdict={'fontsize':15,'fontweight':5,'color':'Brown'})
plt.ylabel("Churn\n",fontdict={'fontsize':15,'fontweight':5,'color':'Brown'})
plt.show()

"""#### Inferences:
- As per the above graph it is clear that Total 2g, 3g data recharge is reducing from June to August and very less in the month of August in comparision to July.
"""

# Create new dataframe from previous one.
Tele_Churn_NW = Tele_Churn.copy(deep=True)

Tele_Churn_NW.shape

Tele_Churn_NW.head()

# TO check the value of the vaiable
Tele_Churn_NW['Age_on_N/W'].value_counts(dropna=False)

# To distibute users Age on Netowrk
AON_dura = [0, 6, 12, 24, 36, 48, 60, 110]
AON_dura_label = ['< 6 Months', '6-12 Months', '1-2 Years', '2-3 Years', '3-4 Years', '4-5 Years', '>= 5 Years']
Tele_Churn_NW['NW_Duration'] = pd.cut(Tele_Churn_NW['Age_on_N/W'], bins = AON_dura, labels = AON_dura_label, duplicates='drop')

# To get the variable values of the dataframe
Tele_Churn_NW['NW_Duration'].head()

# To get the variable values of the dataframe
Tele_Churn_NW.head()

# To get graphical representation of the users Age on Network
plt.figure(figsize=[10,6])
sns.barplot(x='NW_Duration',y='churn', data=Tele_Churn_NW)
plt.title("Users Age on Network\n", fontdict={'fontsize':15,'fontweight':5,'color':'Green'})
plt.xlabel("\nDuration\n",fontdict={'fontsize':15,'fontweight':5,'color':'Brown'})
plt.ylabel("Churn\n",fontdict={'fontsize':15,'fontweight':5,'color':'Brown'})
plt.show()

# To check the shape of the dataframe
Tele_Churn_NW.shape

# Checking the percentage of missing values
round(100*(Tele_Churn_NW.isnull().sum()/len(Tele_Churn_NW.index)), 2)

# To drop the variable from the Dataframe
Tele_Churn_NW.drop(['NW_Duration'], axis=1, inplace=True)

# To check the sahpe of the Dataframe
Tele_Churn_NW.shape

# To get the heads of the dataframe
Tele_Churn_NW.head()

"""### Step 6: Splitting the Data into Training and Testing Sets

- The very first basic step for regression is performing a train-test split.
"""

# Create new dataframe from previous one.
Tele_Churn = Tele_Churn_NW.copy(deep=True)

# Create new dataframe from previous one.
X_Tele_Churn = Tele_Churn.copy(deep=True)

# To check the shape
X_Tele_Churn.shape

# Putting feature variable to X
X = X_Tele_Churn.drop(['mobile_number', 'churn'], axis=1)
X.head()

# To check the shape
X.shape

# Putting response variable to y
y = X_Tele_Churn['churn']
y.head()

# To check the shape
y.shape

# Splitting the data into train and test
np.random.seed(0)
X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=100)

# To check the shape of the Train data
X_train.shape

# To check the shape of the Test data
X_test.shape

# # Checking the percentage of missing values
round(100*(X_train.isnull().sum()/len(X_train.index)), 2)

"""### Step 7: Rescaling the Features 

In Simple Linear Regression, scaling doesn't impact. When variable has little different interger values then rescale the variables to make them comparable. Without comparable scales, some of the coefficients obtained by fitting the regression model might be very large or very small as compared to the other coefficients. This may be very critical during model evaluation. Therefore standardization or normalization should be used so that the units of all the coefficients would be on the same scale. There are two types of rescaling:

1. Standardisation (mean-0, sigma-1)
2. Min-Max scaling : Between 0 and 1

Here, I will use Standardize scaling.

"""

# To check all the variables
X.head()

# To check the shape of the Dataframe
X.shape

# To collect all the numerical variables
Tele_Churn_num = X.select_dtypes(include = ['int64','float64']).columns.tolist()
Tele_Churn_num

# Do scaling on the variables
X_Tele_Churn_scaler = StandardScaler()

# To Fit all the Train data
X_train[Tele_Churn_num] = X_Tele_Churn_scaler.fit_transform(X_train[Tele_Churn_num])

# To Fit all the Test data
X_test[Tele_Churn_num] = X_Tele_Churn_scaler.transform(X_test[Tele_Churn_num])

# To check null values
X_train.isnull().sum()

# To see the type of each column
X_train.info(verbose=True)

# To see the type of each column
X_test.info(verbose=True)

"""### Handeling Data Imbalance

##### With the help of SMOTE(Synthetic Minority Oversampling Technique) minority class elements has been synthesize with already exisitng elements.
  But as this technique is an oversampling technique which may increase the data in the dataframe and which may create an issue, therefore we may use **Weight Balancing** technique.

### Model Selection
#### Inferences
- By using various modeling techniques and on the basis of best value of AUC I will decide the best model to work and get final features.

### Step 8. Building the model using statsmodel, for the detailed statistics.

### Modeling Tecnique 1. 
**RFE with Logistic Regression**
- This time, we will be using the **Logistic Regression function from SciKit Learn** for its compatibility with **RFE** (which is a utility from sklearn).
"""

# Logistic regression model
Churn_logm1 = sm.GLM(y_train,(sm.add_constant(X_train)), family = sm.families.Binomial())
print(Churn_logm1.fit().summary())

"""### Checking VIF

Variance inflation Factor or VIF, gives a basic quantitative idea how much the feature variables are correlated with each other. It is an extremely important parameter to test our linear model. The formula for calculating VIF is:

### $ VIF_i = \frac{1}{1 - {R_i}^2} $

### We could have:
- High P-value, High VIF---Remove these variables
- High-low:
     - High P, low VIF--- Remove these variables first
     - Low P, high VIF--- Remove these after the one above
     - Low P, Low VIF--- Keep these variables
     
     
 - VIF Values
      - VIF < 5 is Good --- no need to eliminate this variable
      - VIF > 5 can be Okay --- need to inspect
      - VIF > 10 is definitely high and the respective variable need to remove
 
 - P value < 0.05 is Good.
"""

# Create a dataframe that will contain the names of all the feature variables and their respective VIFs
vif_1 = pd.DataFrame()
col_1 = X_train.columns
vif_1['Features'] = X_train[col_1].columns
vif_1['VIF'] = [variance_inflation_factor(X_train[col_1].values, i) for i in range(X_train[col_1].shape[1])]
vif_1['VIF'] = round(vif_1['VIF'], 2)
vif_1 = vif_1.sort_values(by = "VIF", ascending = False)
vif_1

# To check shape of the train data
X_train.shape

"""#### Feature Selection Using RFE.
- By using class weight balancing technique.
"""

# Running RFE with the output number of the variable equal to 25 (1: Churned Users (7.9%), 0: Not Churned Users(92.09%))
lgreg_churn = LogisticRegression(class_weight= {1:0.92, 0:0.079})
lgreg_churn.fit(X_train, y_train)

# Running RFE
churn_rfe = RFE(lgreg_churn, 25)            
churn_rfe = churn_rfe.fit(X_train, y_train)

# To make a list of ranked RFE columns
list(zip(X_train.columns, churn_rfe.support_, churn_rfe.ranking_))

# To collect the columns supported by RFE
col_churn = X_train.columns[churn_rfe.support_]
col_churn

# To drop rest of the data from RFE
X_train.columns[~churn_rfe.support_]

"""##### Model 2."""

# Adding A variable
X_train_add = sm.add_constant(X_train[col_churn])

# Running the model
churn_logm2 = sm.GLM(y_train, X_train, family = sm.families.Binomial())
churn_res = churn_logm2.fit()

# To print 
print(churn_res.summary())

# Create a dataframe that will contain the names of all the feature variables and their respective VIFs
churn_vif = pd.DataFrame()
churn_vif['Features'] = X_train[col_churn].columns
churn_vif['VIF'] = [variance_inflation_factor(X_train[col_churn].values, i) for i in range(X_train[col_churn].shape[1])]
churn_vif['VIF'] = round(churn_vif['VIF'], 2)
churn_vif = churn_vif.sort_values(by = "VIF", ascending = False)
round(churn_vif,2)

# Dropping a variable which has higher P and/or higher VIF value
col_churn = col_churn.drop('total_ic_mou_8',1)

# To see the variables
col_churn

# To check shape
col_churn.shape

"""#### Model 3."""

# Adding A variable
X_train_add = sm.add_constant(X_train[col_churn])

# Running the model
churn_logm3 = sm.GLM(y_train, X_train_add, family = sm.families.Binomial())
churn_res = churn_logm3.fit()

# To print 
print(churn_res.summary())

# Create a dataframe that will contain the names of all the feature variables and their respective VIFs
churn_vif = pd.DataFrame()
churn_vif['Features'] = X_train[col_churn].columns
churn_vif['VIF'] = [variance_inflation_factor(X_train[col_churn].values, i) for i in range(X_train[col_churn].shape[1])]
churn_vif['VIF'] = round(churn_vif['VIF'], 2)
churn_vif = churn_vif.sort_values(by = "VIF", ascending = False)
churn_vif

"""#### Model 4."""

# Dropping a variable which has higher P and/or higher VIF value
col_churn = col_churn.drop('Total_local_ic_7', 1)

# To see the variables
col_churn

# To check shape
col_churn.shape

# Adding A variable
X_train_add = sm.add_constant(X_train[col_churn])

# Running the model
churn_logm4 = sm.GLM(y_train, X_train_add, family = sm.families.Binomial())
churn_res = churn_logm4.fit()

# To print 
print(churn_res.summary())

# Create a dataframe that will contain the names of all the feature variables and their respective VIFs
churn_vif = pd.DataFrame()
churn_vif['Features'] = X_train[col_churn].columns
churn_vif['VIF'] = [variance_inflation_factor(X_train[col_churn].values, i) for i in range(X_train[col_churn].shape[1])]
churn_vif['VIF'] = round(churn_vif['VIF'], 2)
churn_vif = churn_vif.sort_values(by = "VIF", ascending = False)
churn_vif

"""##### Inferences:
- This final model (4) seems to be good as all 'P' and 'VIF' values are in control.

"""

# To check various columns and their respective value
X_train_add.head()

# To check the shape of dataframe
X_train_add.shape

"""##### Getting the predicted values on the train set"""

# Getting the predicted values on the train set
y_train_pred = churn_res.predict(X_train_add)
y_train_pred[:10]

# Getting the predicted values on the train set
y_train_pred = y_train_pred.values.reshape(-1)
y_train_pred[:10]

"""#### Creating a dataframe with the actual Conversion flag and the predicted probabilities"""

y_train_pred_final = pd.DataFrame({'Churn':y_train.values, 'Churn_Prob':y_train_pred})
y_train_pred_final['Churn_ID'] = y_train.index
y_train_pred_final.head()

# To rearrange the columns
y_train_pred_final = y_train_pred_final[["Churn_ID", "Churn", "Churn_Prob"]]

# To check the column values
y_train_pred_final.head()

"""##### Creating new column 'Predicted' with 1 if Converted_Prob > 0.5 else 0"""

# Creating new column
y_train_pred_final['Churn_Predicted'] = y_train_pred_final.Churn_Prob.map(lambda x: 1 if x > 0.5 else 0)

# Let's see the head
y_train_pred_final.head()

# Confusion matrix 
churn_rfe_confusion = metrics.confusion_matrix(y_train_pred_final.Churn, y_train_pred_final.Churn_Predicted)
churn_rfe_confusion

# Let's see the Overall Accuracy.
Over_Churn_Acc = round(metrics.accuracy_score(y_train_pred_final.Churn, y_train_pred_final.Churn_Predicted), 2)
print("Overall Accuracy: ", Over_Churn_Acc*100)

"""##### The overall accuracy of the model is **93%**.

#### Plotting of ROC Curve
- An ROC curve demonstrates several things:
It shows the tradeoff between sensitivity and specificity (any increase in sensitivity will be accompanied by a decrease in specificity).
- The closer the curve follows the left-hand border and then the top border of the ROC space, the more accurate the test.
The closer the curve comes to the 45-degree diagonal of the ROC space, the less accurate the test.
"""

def draw_roc(actual, probs):
    fpr, tpr, thresholds = metrics.roc_curve(actual, probs, drop_intermediate = False)
    auc_score = metrics.roc_auc_score(actual, probs)
    plt.figure(figsize=(8, 8))
    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score)
    plt.plot([0, 1], [0, 1], 'k--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate or [1 - True Negative Rate]')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver operating characteristic example')
    plt.legend(loc="lower right")
    plt.show()

    return None

# Find out the ROC variables
fpr, tpr, thresholds = metrics.roc_curve(y_train_pred_final.Churn, y_train_pred_final.Churn_Predicted, drop_intermediate = False )

# To draw ROC curve 
draw_roc(y_train_pred_final.Churn, y_train_pred_final.Churn_Predicted)

"""#### Inferences:
- Here Area under the ROC curve  (AUC) is **96**%.

##### To get Confusion Matrix, Sensitivity, Sfecitivity, Precision, Recall and F1-Score for this model.
"""

# To get Tp, TN, FP, FN
TP_rfe = churn_rfe_confusion[1,1] # true positive 
TN_rfe = churn_rfe_confusion[0,0] # true negatives
FP_rfe = churn_rfe_confusion[0,1] # false positives
FN_rfe = churn_rfe_confusion[1,0] # false negatives

# Check the Sensitivity of our logistic regression model
Churn_Sens_rf = (round(TP_rfe / float(TP_rfe + FN_rfe),2)*100)
print("Sensitivity: ", Churn_Sens_rf)

# Check the calculated Specificity
Churn_Spec_rf = (round(TN_rfe / float(TN_rfe + FP_rfe),2)*100)
print("Specificity: ", Churn_Spec_rf)

# # Calculate False Postive Rate - predicting conversion when user doesn't churned
# FPR_rfe = (round(FP_rfe/float(TN_rfe+FP_rfe),2)*100)
# print("FPR: ", FPR_rfe)

# # Positive Predictive value 
# PP_rfe = (round(TP_rfe / float(TP_rfe+FP_rfe),2)*100)
# print("Positive Predicitve: ", PP_rfe)

# # Negative Predictive Value
# NP_rfe = (round(TN_rfe / float(TN_rfe + FN_rfe),2)*100)
# print("Negative Predictive: ", NP_rfe)

from sklearn.metrics import classification_report
print(classification_report(y_train_pred_final.Churn, y_train_pred_final.Churn_Predicted))

# To find out Precision Score
pre_churn_rfe = (round(precision_score(y_train_pred_final.Churn, y_train_pred_final.Churn_Predicted),2)*100)
print("Precision: ",pre_churn_rfe)

# To find out Recall Score
recall_churn_rfe = (round(recall_score(y_train_pred_final.Churn, y_train_pred_final.Churn_Predicted),2)*100)
print("Recall: ", recall_churn_rfe)

# To get the F1-Score 
F1_Score_rfe = round(2*((pre_churn_rfe * recall_churn_rfe)/(pre_churn_rfe + recall_churn_rfe)),2)
print("F1-Score: ", F1_Score_rfe)

"""#### Inferences RFE before Optimal Point:
- AUC - **96%**
- Accuracy - **93%**
- Sensitivity - **99%**
- Specificity - **92%**
- Precision - **52%**
- Recall - **99%**
- F-Score - **68.19%**

#### Finding Optimal Cutoff Point
- Optimal cutoff probability is that prob where we get balanced sensitivity and specificity
"""

# Let's create columns with different probability cutoffs 
rfe_numbers = [float(x)/10 for x in range(10)]
for i in rfe_numbers:
    y_train_pred_final[i]= y_train_pred_final.Churn_Prob.map(lambda x: 1 if x > i else 0)

# To check the head
y_train_pred_final.head(30)

# Now let's calculate Accuracy, Sensitivity, Specificity, Precision and Recall for various probability cutoffs.
cutoff_rfe = pd.DataFrame(columns = ['Churn_Probs','Accuracy', 'Specificity', 'Sensitivity','Precision', 'Recall'])

# TP_rfe = churn_rfe_confusion[1,1] # true positive 
# TN_rfe = churn_rfe_confusion[0,0] # true negatives
# FP_rfe = churn_rfe_confusion[0,1] # false positives
# FN_rfe = churn_rfe_confusion[1,0] # false negatives

num_rfe = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]
for i in num_rfe:
    cm1_rfe = metrics.confusion_matrix(y_train_pred_final.Churn, y_train_pred_final[i])
    total1=sum(sum(cm1_rfe))
    
    accuracy = (cm1_rfe[0,0]+cm1_rfe[1,1])/total1

    speci = cm1_rfe[0,0]/(cm1_rfe[0,0]+cm1_rfe[0,1])
    sensi = cm1_rfe[1,1]/(cm1_rfe[1,0]+cm1_rfe[1,1])

    Preci = (round(precision_score(y_train_pred_final.Churn, y_train_pred_final[i]),2)*100)
    Recall = (round(recall_score(y_train_pred_final.Churn, y_train_pred_final[i]),2)*100)
    
    cutoff_rfe.loc[i] =[i, accuracy, speci, sensi, Preci, Recall]

# To check output
cutoff_rfe

# To plot accuracy sensitivity and specificity for various probabilities.
cutoff_rfe.plot.line(x='Churn_Probs', y=['Accuracy','Sensitivity','Specificity'])
plt.vlines(0.06, ymax=1, ymin=0, colors='blue',linestyles='dashdot')
plt.legend()
plt.show()

# Selecting 0.06 as a Cut-off point.
y_train_pred_final['final_predicted'] = y_train_pred_final.Churn_Prob.map(lambda x: 1 if x > 0.06 else 0)
y_train_pred_final.head()

# Let's see the Overall Accuracy.
Over_Churn_Acc_2 = round(metrics.accuracy_score(y_train_pred_final.Churn, y_train_pred_final.Churn_Predicted), 2)
print("Overall Accuracy: ", Over_Churn_Acc_2*100)

# To get confusion matrics
churn_rfe_confusion_2 = metrics.confusion_matrix(y_train_pred_final.Churn, y_train_pred_final.Churn_Predicted)
churn_rfe_confusion_2

# To get Tp, TN, FP, FN
TP_rfe_2 = churn_rfe_confusion_2[1,1] # true positive 
TN_rfe_2 = churn_rfe_confusion_2[0,0] # true negatives
FP_rfe_2 = churn_rfe_confusion_2[0,1] # false positives
FN_rfe_2 = churn_rfe_confusion_2[1,0] # false negatives

# Check the Sensitivity of our logistic regression model
Churn_Sens_rf_2 = (round(TP_rfe_2 / float(TP_rfe_2 + FN_rfe_2),2)*100)
print("Sensitivity: ", Churn_Sens_rf_2)

# Check the calculated Specificity
Churn_Spec_rf_2 = (round(TN_rfe_2 / float(TN_rfe_2 + FP_rfe_2),2)*100)
print("Specificity: ", Churn_Spec_rf_2)

# To get model Classification report
print(classification_report(y_train_pred_final.Churn, y_train_pred_final.Churn_Predicted))

"""#### Inferences for RFE on Train Data:
- AUC - **96%**
- Accuracy - **93%**
- Sensitivity - **99%**
- Specificity - **92%**
- Precision - **52%**
- Recall - **99%**
- F-Score - **68%**

#### Prediction on Test Data.
"""

# To Check shape of the Test data
X_test.shape

# To check the variables of the Test data
X_test.head()

col_churn

# Include all the column names in Test data and 
X_test_RFE = X_test[col_churn]
X_test_RFE.head()

# To check the shape
X_test_RFE.shape

# Adding constant
X_test_sm_RFE = sm.add_constant(X_test_RFE)

# Making prediction
y_test_pred_RFE = churn_res.predict(X_test_sm_RFE)

# To get predicted data
y_test_pred_RFE[:10]

# Converting y_test_pred to a dataframe 
y_test_pred_RFE_DT = pd.DataFrame(y_test_pred_RFE)

# To see the variables title
y_test_pred_RFE_DT.head()

# To check the shape
y_test.shape

# To check the head of data
y_test.head()

# Converting y_test to dataframe
y_RFE_test_dt = pd.DataFrame(y_test)

# To see the variables title
y_RFE_test_dt.head()

# Putting Prospect_ID to index
y_RFE_test_dt['Churn_ID'] = y_RFE_test_dt.index

# To see the variables title
y_RFE_test_dt.head()

# Removing index for both dataframes to append them side by side 
y_test_pred_RFE_DT.reset_index(drop=True, inplace=True)
y_RFE_test_dt.reset_index(drop=True, inplace=True)

# To append y_test_pred_data and y_test_data
y_test_pred_RFE_final = pd.concat([y_test_pred_RFE_DT,y_RFE_test_dt], axis=1, join="inner")

# To see the variables title
y_test_pred_RFE_final.head()

# Renaming the column 
y_test_pred_RFE_final = y_test_pred_RFE_final.rename(columns={ 0 : 'Churn_Prob'})

# To see the variables title
y_test_pred_RFE_final.head()

# Rearranging the columns
y_test_pred_RFE_final = y_test_pred_RFE_final[["Churn_ID", "churn", "Churn_Prob"]]

# Let's see the head of y_churn_pred_final
y_test_pred_RFE_final.head(10)

# Creating new column 'Predicted' with 1 if Converted_Prob > 0.5 else 0
y_test_pred_RFE_final['Predicted'] = y_test_pred_RFE_final.Churn_Prob.map(lambda x: 1 if x > 0.5 else 0)

# Let's see the head of the dataframe
y_test_pred_RFE_final.head(10)

# To get overall Test Accuracy
Test_Pred_RFE_Acc = (round(metrics.accuracy_score(y_test_pred_RFE_final.churn, y_test_pred_RFE_final.Predicted), 3)*100)
print("Pred Test Acc of RFE: ", Test_Pred_RFE_Acc)

"""##### Predicated TEST Accuracy for RFE is **92.5%**"""

# To get confusion matrix
Test_RFE_confusn = metrics.confusion_matrix(y_test_pred_RFE_final.churn, y_test_pred_RFE_final.Predicted)
Test_RFE_confusn

# To get Confusion Matrix
TP_RFE_test = Test_RFE_confusn[1,1] # True Positive 
TN_RFE_test = Test_RFE_confusn[0,0] # True Negatives
FP_RFE_test = Test_RFE_confusn[0,1] # False Positives
FN_RFE_test = Test_RFE_confusn[1,0] # False Negatives

# Check the Sensitivity of our logistic regression model on test data
Test_RFE_Sens = (round(TP_RFE_test / float(TP_RFE_test + FN_RFE_test),2)*100)
print("RFE Test Sensitivity: ", Test_RFE_Sens)

# To Check the calculated Specificity for our logistic model on test data
Test_RFE_Spec = (round(TN_RFE_test / float(TN_RFE_test + FP_RFE_test),2)*100)
print("RFE Test Specificity: ", Test_RFE_Spec)

# To find out the value of Precision
prec_RFE_test = round(Test_RFE_confusn[1,1]/(Test_RFE_confusn[0,1] + Test_RFE_confusn[1,1]),2)
print("RFE Test Precision: ", prec_RFE_test * 100)

# To find out the value of Recall
recall_RFE_test = round(Test_RFE_confusn[1,1]/(Test_RFE_confusn[1,0] + Test_RFE_confusn[1,1]),2)
print("RFE Test Recall: ", recall_RFE_test*100)

# To get the F1-Score 
F1_RFE_Score_Test = round(2*((prec_RFE_test * recall_RFE_test)/(prec_RFE_test + recall_RFE_test)),2)
print("RFE Test F1_Score: ", F1_RFE_Score_Test * 100)

# To get classification report
print(classification_report(y_test_pred_RFE_final.churn, y_test_pred_RFE_final.Predicted))

"""### Inferences:
- RFE Overall Test Accuracy: **92%**
- RFE Test Sensitivity: **99%**
- RFE Test Specifitivity: **92%**
- RFE Test Precision: **52%**
- RFE Test Recall: **99%**
- RFE Test F-Score: **68%**

#### Plotting of ROC Curve on Test Data
"""

def draw_roc(actual, probs):
    fpr, tpr, thresholds = metrics.roc_curve(actual, probs, drop_intermediate = False)
    auc_score = metrics.roc_auc_score(actual, probs)
    plt.figure(figsize=(8, 8))
    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score)
    plt.plot([0, 1], [0, 1], 'k--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate or [1 - True Negative Rate]')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver operating characteristic example')
    plt.legend(loc="lower right")
    plt.show()

    return None

# Test_Pred_RFE_Acc

# Find out the ROC variables
fpr, tpr, thresholds = metrics.roc_curve(y_test_pred_RFE_final.churn, y_test_pred_RFE_final.Predicted, drop_intermediate = False )

# To draw ROC curve 
draw_roc(y_test_pred_RFE_final.churn, y_test_pred_RFE_final.Predicted)

"""#### AUC of ROC curve is **95%** for the Test data of RFE.

### Modeling Technique 2

#### **Random Forest**
"""

# To get the shape of Train data
X_train.shape

# To get details of all variables
X_train.head()

# To get Random Forest with upto 50 Trees
RFS_Churn = RandomForestClassifier(bootstrap=True, 
                                   class_weight= {1:0.92, 0:0.079},
                                   random_state=42,
                                   min_samples_leaf=150, 
                                   min_samples_split=300,
                                   max_features='auto', 
                                   n_estimators=50, 
                                   oob_score=True,
                                   max_depth=15)

# To fit X_train data
RFS_Churn.fit(X_train, y_train)

# To get Estimator
RFS_Churn.estimators_[0]

# To Predict the test data
RFS_pred = RFS_Churn.predict(X_test)

# To get classification report
print(classification_report(y_test, RFS_pred))

"""#### Inferences for Random Forest:
- Overall Accuracy: **98%**
- Precision: **78%**
- Recall: **100%**
- F1-Score: **88%**
"""

# # A function to get decision Tree
# def get_dt_graph(dt_classifier):
#     dot_data = StringIO()
#     export_graphviz(dt_classifier, out_file = dot_data, filled=True,rounded=True,
#                     feature_names=X.columns, 
#                     class_names=['Churn', "Not Churn"])
#     graph = pydotplus.graph_from_dot_data(dot_data.getvalue())
#     return graph

# A function to evaluate the model
def evaluate_model(dt_classifier):
    print("Train Accuracy :", accuracy_score(y_train, dt_classifier.predict(X_train)))
    print("Train Confusion Matrix:")
    print(confusion_matrix(y_train, dt_classifier.predict(X_train)))
    print("-"*50)
    print("Test Accuracy :", accuracy_score(y_test, dt_classifier.predict(X_test)))
    print("Test Confusion Matrix:")
    print(confusion_matrix(y_test, dt_classifier.predict(X_test)))

# To evaluate the model
evaluate_model(RFS_Churn)

"""#### Inferences for Random Forest:
- Train Accuracy: **98.11%**
- Test Accuracy: **97.75%**
"""

# # To get the sample tree
# sample_tree = RFS_Churn.estimators_[4]

# # To get graphical presentation
# gph = get_dt_graph(sample_tree)
# Image(gph.create_png(), width=1000, height=400)

"""#### Grid search to find optimal parameters for Random Forest."""

# To make parameter grid in the basis of random search
par_churn_grid = {
    'max_depth': [1, 2, 5, 10, 20],
    'min_samples_leaf': range(10, 20, 30),
    'min_samples_split': range(10, 30, 50),
    'n_estimators': [5, 10, 15, 20, 30, 50], 
    'max_features': [5, 10, 15, 20, 25, 30]
}

# To make a base model
RFS = RandomForestClassifier(random_state = 42, class_weight= {1:0.92, 0:0.079}, n_jobs = -1)

# To initiate the grid search model
churn_grid_search = GridSearchCV(estimator=RFS, param_grid = par_churn_grid, 
                          cv=4, n_jobs=-1, verbose=1, scoring = "accuracy")

# To fit the grid search with the data
churn_grid_search.fit(X_train, y_train)

# To get optimal Accuracy Score and Hyperparameters
print('Optimal Accuracy is: ', round(churn_grid_search.best_score_, 4)*100 ,  'with best hyperparameters: ', churn_grid_search.best_params_)

# To get the best estimator
RFS_best = churn_grid_search.best_estimator_

# To get the best estimators
RFS_best

# Evaluate model with the best estimators
evaluate_model(RFS_best)

"""### Fitting the best model"""

# To do model with best hyperparamter
# from sklearn.ensemble import RandomForestClassifier
RFS_2 = RandomForestClassifier(bootstrap=True,
                               class_weight={0: 0.079, 1: 0.92},
                               max_depth=1,
                               min_samples_leaf=10, 
                               min_samples_split=10,
                               max_features=25,
                               n_estimators=10)

# To fit the model on train data
RFS_2.fit(X_train, y_train)

# To predict model on Test data
RFS_Test_Pred = RFS_2.predict(X_test)

# To get classification report
print(classification_report(y_test, RFS_Test_Pred))

"""### Inferences for Random Forest Final Model
- Overall Accuracy - **100%**
- Precision - **100%**
- Recall - **100%**
- F1-Score - **100%**

### Feature Selection
"""

# To get the list of important features
Churn_featre_name = list(X_train.columns.values)
imp_fetre_dict = {}

for name, importance in zip(Churn_featre_name, RFS_2.feature_importances_):
    imp_fetre_dict[name] = importance

# To sort the dictionary in descending order
d_descending = OrderedDict(sorted(imp_fetre_dict.items(), 
                                  key=lambda kv: kv[1], reverse=True))

# To check various columns of dataframe
X_Tele_Churn.columns

# Top 5 important features
dic= dict(d_descending)

def take(n, iterable):
    "Return first n items of the iterable as a list"
    return list(islice(iterable, n))

n = 5
n_items = take(n, dic.items())

# To get the top 5 influencers.
print('Top 5 influencer features: ', n_items)

# To get graphical representation of top 5 features
imp = RFS_2.feature_importances_
names = X_train.columns.values
imp,names=zip(*sorted(zip(imp, names)))

Churn_A = pd.DataFrame({"Variable":names,"importance":imp})
Churn_B = Churn_A.sort_values(by="importance", axis=0, ascending=False)
Churn_B = Churn_B.reset_index(drop=True)

fig = plt.figure(figsize=(10,7))
sns.barplot(x='Variable', y='importance', data = Churn_B[0:5])
plt.title("Various Feature Importance\n", fontdict={'fontsize':20,'fontweight':5,'color':'Green'})
plt.xlabel("\nTop 5 Features\n",fontdict={'fontsize':15,'fontweight':5,'color':'Brown'})
plt.ylabel("Feature Importance\n",fontdict={'fontsize':15,'fontweight':5,'color':'Brown'})
plt.xticks(rotation=90)
plt.show()

"""### Inferences Random Forest Features:
- Top 5 variables are as followings:
- Overall Usage of minutes is the highest influencer among all other features.
- Total_og_mou_8 which includes all the outgoing calls on various network and having top 2nd influencer of Churn.
- Average Revenue Per User (arpu_8) is the top 3rd influencer which affects the Churn rate.
- Total_local_ic_8 which includes various incoming calls and it is the top 4th influencer of Churn rate.

### Model 3. 
**XGBoost**
"""

# To get XGBoost Classifier
xgclf_churn = xgb.XGBClassifier(class_weight= {1:0.92, 0:0.079})

# To fit the XGBoost
xgclf_churn.fit(X_train, y_train)

# To get AUC of Train data
print("XGBoost AUC of Train Data: ", metrics.roc_auc_score(y_true = y_train,
                                                              y_score = xgclf_churn.predict_proba(X_train)[:, 1]))

# To get AUC of Test data
print("XGBoost AUC of Test Data: ", metrics.roc_auc_score(y_true = y_test,
                                                             y_score = xgclf_churn.predict_proba(X_test)[:, 1]))

"""#### Inferences of XGBoost before Hyper Parameter Tunning:
- AUC of Train Data: **100%**
- AUC of Tet Data: **100%**

#### Hyper parameter Tunning
"""

# To get XGB model
xgb_churn_model = xgb.XGBClassifier(class_weight= {1:0.92, 0:0.079})

# Default Hyperparameter run for default parameter
xgb_param = {'learning_rate': [0.3],
              'max_depth': [6],
              'min_child_weight': [1],
              'n_estimators': [100]}

xgb_scorer = metrics.make_scorer(metrics.roc_auc_score,
                             greater_is_better = True,
                             needs_proba = True,
                             needs_threshold = False)

clf_xgb_churn = model_selection.GridSearchCV(estimator = xgb_churn_model,
                                             param_grid = xgb_param,
                                             n_jobs = -1,
                                             cv = 3,
                                             scoring = xgb_scorer,
                                             refit = True)

# To fit Train data with XGBoost
clf_xgb_churn.fit(X_train, y_train)

# To get best XGBoost Hyper Parameter, Score and the Estimator
print("Best XGBoost Parameter: ", clf_xgb_churn.best_params_)
print("Best XGBoost Score: ", clf_xgb_churn.best_score_)
print("Best XGBoost Estimator: ", clf_xgb_churn.best_estimator_)

"""#### 1st Run for Hperparameter Selection"""

# 1st-Run for best hyperparameters
xgb_param = {'learning_rate': [0.1, 0.2, 0.3, 0.4, 0.5],
              'max_depth': [2, 4, 6, 8, 10],
              'min_child_weight': [3, 7, 11, 19, 25],
              'n_estimators': [5, 10, 15, 20, 30, 50]}

xgb_scorer = metrics.make_scorer(metrics.roc_auc_score,
                                 greater_is_better = True,
                                 needs_proba = True,
                                 needs_threshold = False)

clf_xgb_churn = model_selection.GridSearchCV(estimator = xgb_churn_model,
                                             param_grid = xgb_param,
                                             n_jobs = -1,
                                             cv = 3,
                                             scoring = xgb_scorer,
                                             refit = True)

# To fit Train data with new Hyperparameter
clf_xgb_churn.fit(X_train, y_train)

# To get 1st XGBoost Hyper Parameter, Score and the Estimator
print("1st Best XGBoost Parameter: ", clf_xgb_churn.best_params_)
print("1st Best XGBoost Score: ", clf_xgb_churn.best_score_)
print("1st Best XGBoost Estimator: ", clf_xgb_churn.best_estimator_)

"""#### To get Final XGBoost Model"""

# To get final XGBoost Classifier
final_xgb_model = xgb.XGBClassifier(learning_rate = 0.1,
                                    class_weight= {1:0.92, 0:0.079},
                                    max_depth = 2,
                                    min_child_weight = 3,
                                    n_estimators = 5)

# To fit Final XGBoost model
final_xgb_model.fit(X_train, y_train)

# To get AUC of Train data
print("Final XGBoost AUC of Train Data: ", metrics.roc_auc_score(y_true = y_train,
                                                                  y_score = final_xgb_model.predict_proba(X_train)[:, 1]))

# To get AUC of Test data
print("Final XGBoost AUC of Test Data: ", metrics.roc_auc_score(y_true = y_test,
                                                                y_score = final_xgb_model.predict_proba(X_test)[:, 1]))

"""### Inferences for Final Model of XGBoost:
- AUC of Train Data:- **100%**
- AUC of Test Data:- **100%**

### Model 4.

### **Ridge Regression**
"""

# list of alphas to tune
ridge_params = {'alpha': [0.0001, 0.001, 0.01, 0.05, 0.1, 
 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0, 
 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 50, 100, 500, 1000 ]}

ridge = Ridge()

# cross validation
folds = 5
churn_cv = GridSearchCV(estimator = ridge, 
                        param_grid = ridge_params, 
                        scoring= 'r2',
                        cv = folds, 
                        return_train_score=True,
                        verbose = 1)

# To fit Train data with Ridge
churn_cv.fit(X_train, y_train)

# To see resultant output of Alpha values
churn_cv_reslt = pd.DataFrame(churn_cv.cv_results_)
churn_cv_reslt.head()

# To plot mean test and train scores with alpha values 
churn_cv_reslt['param_alpha'] = churn_cv_reslt['param_alpha'].astype('int32')

# To plot the graph
plt.figure(figsize=(15,6))
plt.plot(churn_cv_reslt['param_alpha'], churn_cv_reslt['mean_train_score'])
plt.plot(churn_cv_reslt['param_alpha'], churn_cv_reslt['mean_test_score'])
plt.xlabel("\nAlpha\n",fontdict={'fontsize':15,'fontweight':5,'color':'Brown'})
plt.ylabel("R-Squared Value\n",fontdict={'fontsize':15,'fontweight':5,'color':'Brown'})
plt.title("R-Squared and Alpha\n",fontdict={'fontsize':15,'fontweight':5,'color':'Brown'})
plt.legend(['Train Score', 'Test Score'], loc='upper right')
plt.xlim(0, 100)
plt.xticks(np.arange(0, 100, 5))
plt.grid(color='g', linestyle='--', linewidth=1)
plt.show()

# To get the Best Estimator, Best Score, and Best Parameters
print("\n Best Score among aLL searched parameters:\n",
          churn_cv.best_score_)

print("\n Best Estimator among aLL searched parameters:\n",
          churn_cv.best_estimator_)

# To check with the best hyper paramter value
alpha_50 = 50
ridge = Ridge(alpha=alpha_50)
ridge.fit(X_train, y_train)

# To see all the Ridge Coeffecients
ridge.coef_

# To Predict Train and Test data
y_train_pred = ridge.predict(X_train)
print(metrics.r2_score(y_true=y_train, y_pred=y_train_pred))

y_test_pred_ridge = ridge.predict(X_test)
print(metrics.r2_score(y_true=y_test, y_pred=y_test_pred_ridge))

"""#### Inferences for Ridge Regression
- R2 Score for Train data is **28.83%**
- R2 Score for Test data is **27.73%**

#### Conclusion
- As R2-Sscore for Train and Test data is very low , we can say that this model is not performing well.

### Model 5. (PCA with Logistic Regression)
"""

#Import the PCA 
pca_churn = PCA(svd_solver='randomized', random_state=42)

# Do PCA on Train data
pca_churn.fit(X_train)

# To see PCA components
pca_churn.components_

# To see top 5 PCA component
churn_cols = list(X_train.columns)
pca_churn_data = pd.DataFrame({'PC1':pca_churn.components_[0],'PC2':pca_churn.components_[1], 
                               'PC3':pca_churn.components_[2],'PC4':pca_churn.components_[3],
                               'PC5':pca_churn.components_[4],
                              #  'PC6':pca_churn.components_[5], 'PC7':pca_churn.components_[6],'PC8':pca_churn.components_[7],
                              #  'PC9':pca_churn.components_[8],'PC10':pca_churn.components_[9],
                              #  'PC11':pca_churn.components_[10], 'PC12':pca_churn.components_[11],
                              #  'PC13':pca_churn.components_[12],'PC14':pca_churn.components_[13],
                              #  'PC15':pca_churn.components_[14],
                               'Feature':churn_cols})
pca_churn_data.head(25)

# To check PCA Variance Ratio
np.cumsum(pca_churn.explained_variance_ratio_)

# To analyze features with PCA plotting
fig = plt.figure(figsize = (10,7))
plt.plot(np.cumsum(pca_churn.explained_variance_ratio_))
plt.vlines(x=27, ymax=1, ymin=0, colors="r", linestyles="--")
plt.hlines(y=0.90, xmax=30, xmin=0, colors="g", linestyles="--")
plt.title("PCA Components Vs Variance\n", fontdict={'fontsize':20,'fontweight':5,'color':'Green'})
plt.xlabel("\nComponents",fontdict={'fontsize':15,'fontweight':5,'color':'Brown'})
plt.ylabel("\nCumulative Variance\n",fontdict={'fontsize':15,'fontweight':5,'color':'Brown'})
plt.show()

"""#### Nearly 27 features are showing 90% variance """

# To fit train data with final PCA component
# pca_churn_final = IncrementalPCA(n_components=27)
pca_churn_final = PCA(n_components=27, random_state=42)
X_train_fin_pca = pca_churn_final.fit_transform(X_train)

# To check the shape of the dataframe
X_train_fin_pca.shape

# To fit Test data with final PCA components
X_test_fin_pca = pca_churn_final.transform(X_test)

# To check the shape of the dataframe
X_test_fin_pca.shape

"""### PCA Logistic Regression with Class Weight Balancing technique."""

# Train the regression model
log_pca = LogisticRegression(class_weight= {1:0.92, 0:0.079})
model_pca = log_pca.fit(X_train_fin_pca, y_train)

# To get Accuracy Score
print("Accuracy: ", round(model_pca.score(X_train_fin_pca, y_train) * 100, 2))

"""#### Overall Accuracy of model with PCA: **87.46%**"""

# Prediction on Train data
y_train_pred = log_pca.predict_proba(X_train_fin_pca)

# To convert y_train_pred to a dataset
y_train_pred_data = pd.DataFrame(y_train_pred)

# To convert into column 
y_train_pred_data = y_train_pred_data.iloc[:,[1]]

# To check the columns and their values
y_train_pred_data.head(10)

# To convert y_test data to a dataframe
y_test_data = pd.DataFrame(y_test)

# To check the columns and their values
y_test_data.head(10)

# To check the Null value in the Dataframe
y_test_data.isnull().sum()

# Putting Churn_ID to index
y_test_data['Churn_ID'] = y_test_data.index

# To check the columns and their values
y_test_data.head(10)

# To check the Null value in the Dataframe
y_test_data.isnull().sum()

# Removing index for both dataframes to append them side by side 
y_train_pred_data.reset_index(drop=True, inplace=True)
y_test_data.reset_index(drop=True, inplace=True)

# Appending y_train_pred_data and y_test_data
y_churn_pred_final = pd.concat([y_test_data, y_train_pred_data], axis=1, join="inner")

# To check the columns and their values 
y_churn_pred_final.head(10)

# To check the Null value in the Dataframe
y_churn_pred_final.isnull().sum()

# Renaming the column 
y_churn_pred_final.rename(columns={ 1 : 'Tele_Churn_Prob'}, inplace = True)

# To check the columns values in Dataframe
y_churn_pred_final.head()

# To check the Null value in the Dataframe
y_churn_pred_final.isnull().sum()

# Rearranging the columns
# y_churn_pred_final = y_churn_pred_final.reindex(['Churn_ID','Churn','Tele_Churn_Prob'], axis=1)
y_churn_pred_final = y_churn_pred_final[["Churn_ID", "churn", "Tele_Churn_Prob"]]

# Let's see the head of y_churn_pred_final
y_churn_pred_final.head(10)

# To check the Null value in the Dataframe
y_churn_pred_final.isnull().sum()

"""### Creating new column 'Predicted' with 1 if Converted_Prob > 0.5 else 0."""

# Creating new column
y_churn_pred_final['Predicted'] = y_churn_pred_final.Tele_Churn_Prob.map(lambda x: 1 if x > 0.5 else 0)

# To Check the column titles/variable's name of dataframe
y_churn_pred_final.head()

# Confusion matrix 
churn_confusion = metrics.confusion_matrix(y_churn_pred_final.churn, y_churn_pred_final.Predicted)
churn_confusion

# Let's see the overall accuracy.
Over_Churn_Acc = (round(metrics.accuracy_score(y_churn_pred_final.churn, y_churn_pred_final.Predicted), 3)*100)
print("Over_Churn_Acc: ", Over_Churn_Acc)

"""### Inferences for PCA for Train data: 
#### Overall Train Accuracy is **76.5%**.

### Metrics beyond simply accuracy
"""

# To get Tp, TN, FP, FN
TP = churn_confusion[1,1] # true positive 
TN = churn_confusion[0,0] # true negatives
FP = churn_confusion[0,1] # false positives
FN = churn_confusion[1,0] # false negatives

# Check the Sensitivity of our logistic regression model
Churn_Sens = (round(TP / float(TP+FN),2)*100)
print("Sensitivity: ", Churn_Sens)

# Check the calculated Specificity
Churn_Spec = (round(TN / float(TN+FP),2)*100)
print("Specificity: ", Churn_Spec)

# # Calculate False Postive Rate - predicting conversion when user doesn't churned
# Churn_FPR = (round(FP/ float(TN+FP),2)*100)
# print("FPR: ", Churn_FPR)

# # Positive Predictive value 
# Churn_PP = (round(TP / float(TP+FP),2)*100)
# print("Positive Predicitve: ", Churn_PP)

# # Negative Predictive Value
# Churn_NP = (round(TN / float(TN+ FN),2)*100)
# print("Negative Predictive: ", Churn_NP)

"""#### Inferences for PCA on Train data with Logistic Regression:
- Accuracy - **87.5%**
- Sensitivity - **6%**
- Specificity - **95%**

### Precision
"""

# To find out Precision Score
pre_churn_1 = (round(precision_score(y_churn_pred_final.churn, y_churn_pred_final.Predicted),2)*100)
print("Precision: ",pre_churn_1)

"""### Recall"""

# To find out Recall Score
recall_churn_1 = (round(recall_score(y_churn_pred_final.churn, y_churn_pred_final.Predicted),2)*100)
print("Recall: ", recall_churn_1)

"""### F1-Score"""

# To get the F1-Score 
F1_Score_1 = round((2*((pre_churn_1 * recall_churn_1)/(pre_churn_1 + recall_churn_1))),2)
print("F1-Score: ", F1_Score_1)

"""### F1-Score is 11.26%

### Plotting ROC Curve.

#### An ROC curve demonstrates several things:

- It shows the tradeoff between sensitivity and specificity (any increase in sensitivity will be accompanied by a decrease in specificity).
- The closer the curve follows the left-hand border and then the top border of the ROC space, the more accurate the test.
- The closer the curve comes to the 45-degree diagonal of the ROC space, the less accurate the test.
"""

def draw_roc(actual, probs):
    fpr, tpr, thresholds = metrics.roc_curve(actual, probs, drop_intermediate = False)
    auc_score = metrics.roc_auc_score(actual, probs)
    plt.figure(figsize=(8, 8))
    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score)
    plt.plot([0, 1], [0, 1], 'k--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate or [1 - True Negative Rate]')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver operating characteristic example')
    plt.legend(loc="lower right")
    plt.show()

    return None

# Find out the ROC variables
fpr, tpr, thresholds = metrics.roc_curve(y_churn_pred_final.churn, y_churn_pred_final.Predicted, drop_intermediate = False )

# To draw ROC curve 
draw_roc(y_churn_pred_final.churn, y_churn_pred_final.Predicted)

"""#### Inferences for PCA before optimal point:
- Here Area under the ROC curve (AUC) is **50**%.

### Finding Optimal Cutoff Point.
- Optimal cutoff probability is that prob where we get balanced sensitivity and specificity.
"""

# Let's create columns with different probability cutoffs 
numbers = [float(x)/10 for x in range(10)]
for i in numbers:
    y_churn_pred_final[i]= y_churn_pred_final.Tele_Churn_Prob.map(lambda x: 1 if x > i else 0)

# To check the head
y_churn_pred_final.head()

# To calculate Accuracy, Sensitivity, Specificity, Precision and Recall for various probability cutoffs.
cutoff_df = pd.DataFrame(columns = ['Conv_Probs','Accuracy', 'Specificity', 'Sensitivity','Precision', 'Recall'])

# TP = churn_confusion[1,1] # true positive 
# TN = churn_confusion[0,0] # true negatives
# FP = churn_confusion[0,1] # false positives
# FN = churn_confusion[1,0] # false negatives

num = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]
for i in num:
    cm1 = metrics.confusion_matrix(y_churn_pred_final.churn, y_churn_pred_final[i] )
    total1=sum(sum(cm1))
    
    accuracy = (cm1[0,0]+cm1[1,1])/total1

    speci = cm1[0,0]/(cm1[0,0]+cm1[0,1])
    sensi = cm1[1,1]/(cm1[1,0]+cm1[1,1])

    Preci = (round(precision_score(y_churn_pred_final.churn, y_churn_pred_final[i]),2)*100)
    Recall = (round(recall_score(y_churn_pred_final.churn, y_churn_pred_final[i]),2)*100)
    
    cutoff_df.loc[i] =[i, accuracy, speci, sensi, Preci, Recall]

# To get output 
cutoff_df

# To plot accuracy sensitivity and specificity for various probabilities.
cutoff_df.plot.line(x='Conv_Probs', y=['Accuracy','Sensitivity','Specificity'])
plt.vlines(0.1, ymax=1, ymin=0, colors='blue',linestyles='dashdot')
plt.legend()
plt.show()

# Selecting 0.1 as a Cut-off point.
y_churn_pred_final['New_predicted'] = y_churn_pred_final.Tele_Churn_Prob.map(lambda x: 1 if x > 0.1 else 0)
y_churn_pred_final.head()

New_Churn_Acc = (round(metrics.accuracy_score(y_churn_pred_final.churn, y_churn_pred_final.Predicted), 3)*100)
print("New Overall Acc: ", New_Churn_Acc)

# Confusion matrix 
churn_confusion_2 = metrics.confusion_matrix(y_churn_pred_final.churn, y_churn_pred_final.Predicted)
churn_confusion_2

# To find out the value of Precision
pre_churn_2 = round(churn_confusion_2[1,1]/(churn_confusion_2[0,1]+churn_confusion_2[1,1]),2)
print("Precision: ", pre_churn_2*100)

# To find out the value of Recall
recall_churn_2 = round(churn_confusion_2[1,1]/(churn_confusion_2[1,0]+churn_confusion_2[1,1]),2)
print("Recall: ", recall_churn_2*100)

# To get the F1-Score 
F1_Score_2 = round(2*((pre_churn_2 * recall_churn_2)/(pre_churn_2 + recall_churn_2)),2)
print("F1_Score: ", F1_Score_2*100)

"""### Inferences for PCA on Train data after Optimal Point:
- New Overall Accuracy: **76.5%**
- Precision: **8%**
- Recall: **19%**
- F-1 Score: **11%**

#### PCA on Test data
"""

# To Check shape of the Test data
X_test.shape

# To check the variables of the Test data
X_test.head()

# To check the shape of the Test dataframe with PCA
X_test_fin_pca.shape

# To check the variable value
y_test.head(10)

# To get overall Test Accuracy
test_churn_pred = model_pca.predict_proba(X_test_fin_pca)[:,1]
"{:2.2}".format(metrics.roc_auc_score(y_test, test_churn_pred))

"""#### Overall PCA Test Accuracy is **93%**.

#### To Predict Test Probability
"""

# To get Predicted test probabilities
y_test_pred_pca = log_pca.predict_proba(X_test_fin_pca)

# Converting y_test_pred to a dataframe 
y_test_pred_pca_data = pd.DataFrame(y_test_pred_pca)

# To convert test data into dataframe
y_test_pred_pca_data = y_test_pred_pca_data.iloc[:,[1]]

# To check the head
y_test_pred_pca_data.head()

# To remove for both dataframes to append them side by side 
y_test_pred_pca_data.reset_index(drop=True, inplace=True)
y_test_data.reset_index(drop=True, inplace=True)

# To append y_test_pred_data and y_test_data
y_test_pred_final = pd.concat([y_test_data, y_test_pred_pca_data], axis=1, join="inner")

# To check the columns and their values 
y_test_pred_final.head(10)

# To check the Null value in the Dataframe
y_test_pred_final.isnull().sum()

# Renaming the column 
y_test_pred_final.rename(columns={ 1 : 'Test_Prob'}, inplace = True)

# To check the columns values in Dataframe
y_test_pred_final.head()

# To check the Null value in the Dataframe
y_test_pred_final.isnull().sum()

# Rearranging the columns
y_test_pred_final = y_test_pred_final[["Churn_ID", "churn", "Test_Prob"]]

# Let's see the head of y_churn_pred_final
y_test_pred_final.head(10)

# Creating new column 'Predicted' with 1 if Converted_Prob > 0.5 else 0
y_test_pred_final['Predicted'] = y_test_pred_final.Test_Prob.map( lambda x: 1 if x > 0.5 else 0)

# Let's see the head
y_test_pred_final.head()

# To get overall Test Accuracy
Test_Pred_Acc = (round(metrics.accuracy_score(y_test_pred_final.churn, y_test_pred_final.Predicted), 3)*100)
print("Pred Test Acc: ", Test_Pred_Acc)

# To get confusion matrix
Test_confusn = metrics.confusion_matrix(y_test_pred_final.churn, y_test_pred_final.Predicted )
Test_confusn

# To get Confusion Matrix
TP_test = Test_confusn[1,1] # True Positive 
TN_test = Test_confusn[0,0] # True Negatives
FP_test = Test_confusn[0,1] # False Positives
FN_test = Test_confusn[1,0] # False Negatives

# Check the Sensitivity of our logistic regression model on test data
Test_Sens = (round(TP_test / float(TP_test + FN_test),2)*100)
print("Test Sensitivity: ", Test_Sens)

# To Check the calculated Specificity for our logistic model on test data
Test_Spec = (round(TN_test / float(TN_test + FP_test),2)*100)
print("Test Specificity: ", Test_Spec)

# To find out the value of Precision
prec_test = round(Test_confusn[1,1]/(Test_confusn[0,1] + Test_confusn[1,1]),2)
print("Test Precision: ", prec_test * 100)

# To find out the value of Recall
recall_test = round(Test_confusn[1,1]/(Test_confusn[1,0] + Test_confusn[1,1]),2)
print("Test Recall: ", recall_test*100)

# To get the F1-Score 
F1_Score_Test = round(2*((prec_test * recall_test)/(prec_test + recall_test)),2)
print("Test F1_Score: ", F1_Score_Test * 100)

"""#### Inferences for PCA on Test Data:
- Probability of Predicted Test Accuracy: **86.3%**
- Sensitivity on Test Data: **87%**
- Specificity on Test Data: **86%**
- Precision on Test Data: **36%**
- Recall on Test Data: **87%**
- Test F1-Score: **51%**

### Module Selection:
- After various model calcualtions I found that among all the models including RFE, XGBoost, Ridge Regression and PCA, Random Forest is one of the most useful Model for our purpose. As its overall Accuracy, Precision and Recall are **100%** and its gives top 5 most useful features for observation.

### Conclusion/Outcome:
- According to feature importance graph of Random Forest it is clear that Company should consider 4 following different features to control Churn Rate...
- Overall Usage, and from the month of August Total_og_mou_8, arpu_8, Total_local_ic_8, if they go down then Churn rate may increase, therefore during this phase and on variation of these values for that particular customer company should provide offers to that no.
- As they all are related to the month of August company should consider this duration and should do accordingly.

-According to various EDA graphs it is concluded that from June to August users overall data usage, total local outgoing, total std outgoing, total recharge amount has been decreased from June to August.
- Whereas reachrging no. of days has been increased for the Churned users therfore company need to observe all these parameters and do accordingly to retain the users.

### ***End of Telecomm Churn with Logistic Regression***
"""