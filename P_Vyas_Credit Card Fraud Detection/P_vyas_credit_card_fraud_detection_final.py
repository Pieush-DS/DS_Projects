# -*- coding: utf-8 -*-
"""P_Vyas_Credit Card Fraud Detection_Final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KQ_9um2CdHzd_MB-_eWkSUH2_nujOov9

# <font color = blue> Credit Card Fraud Detection  </font>
### Problem Statement:
In this project you will predict fraudulent credit card transactions with the help of Machine learning models. Analyse customer-level data that has been collected and analysed during a research collaboration of Worldline and the Machine Learning Group.

### Business Problem:
Many banks, retaining high profitable customers is the number one business goal. Banking fraud, however, poses a significant threat to this goal for different banks. In terms of substantial financial losses, trust and credibility, this is a concerning issue to both banks and customers alike.

### Understanding and defining Fraud:
Credit card fraud is any dishonest act or behaviour to obtain information without proper authorisation from the account holder for financial gain. Among different ways of committing frauds, skimming is the most common one, which is a way of duplicating information that is located on the magnetic strip of the card.

There are few other ways of Credit Card Fraud:
- Manipulation/alteration of genuine cards
- Creation of counterfeit cards
- Stealing/loss of credit cards
- Fraudulent telemarketing
"""

# Suppressing Warnings
import warnings
warnings.filterwarnings('ignore')

# Commented out IPython magic to ensure Python compatibility.
# Import imortant libraries
import numpy as np
import pandas as pd
import time

import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns

from sklearn import metrics
from sklearn import preprocessing
from sklearn.preprocessing import PowerTransformer

import warnings
warnings.filterwarnings('ignore')

# To set the Row, Column and Width of the Dataframe to show on Jupyter Notebook
pd.set_option('display.max_rows',1000)
pd.set_option('display.max_columns',500)
pd.set_option('display.width',1000)

"""## Importing and Reading the Data"""

# To read given dataset
CC_Fraud = pd.read_csv("C:/Users/lenovo/Documents/upGrad/Capstone Project/creditcard.csv")

# Create new dataframe from previous one.
df = CC_Fraud.copy(deep=True)

# To check all the variables labels
df.head()

"""## Inspecting the Data Frame
Inspect the dataframe for dimensions, null-values, and summary of different numeric columns.
"""

# To create a required function for count, null, Precent, Unique values and the Datatype
def CC_info(datafr):
    count = datafr.count()
    null = datafr.isnull().sum()
    null_perc = round(datafr.isnull().sum()/len(datafr.index)*100,4)
    unique = datafr.nunique()
    types = datafr.dtypes
    return pd.concat([count, null, null_perc, unique, types],
                     axis = 1,keys=['COUNT','NULL','PERCENT','UNIQUE','DATATYPE']).sort_values(by='PERCENT',ascending=False)

# To Check the dimensions of the dataframe
df.shape

# To check the dataframe details
CC_info(CC_Fraud)

"""## Exploratory data analysis

#### Here we will observe the distribution of our classes
"""

# Distribution of Fraudlenet and Non-Fraudulent classes
classes = CC_Fraud['Class'].value_counts()
normal_share = classes[0]/CC_Fraud['Class'].count()*100
fraud_share = classes[1]/CC_Fraud['Class'].count()*100

# To print the normal and fraud share
print("normal_share: ",normal_share,"            ","fraud_share: ",fraud_share)

imbalance= (fraud_share/normal_share)*100
print('Imbalance Percentage: ' + str(imbalance))

# Create a bar plot for the number and percentage of fraudulent vs non-fraudulent transcations
fig, ax = plt.subplots(1, 2, figsize=(18,4))

classes.plot(kind='bar', rot=0, ax=ax[0])
ax[0].set_title('Number of Class Distributions \n (0: No_Fraud, 1: Fraud)\n', fontdict={'fontsize':15,'fontweight':5,'color':'Green'})

(classes/df['Class'].count()*100).plot(kind='bar', rot=0, ax=ax[1])
ax[1].set_title('Percentage of Distributions \n (0: No_Fraud, 1: Fraud)\n', fontdict={'fontsize':15,'fontweight':5,'color':'Green'})

plt.show()

"""## Inferences:
As per the aobve bar graphs Fraudulent cases are very less than Non-Fraudulent cases.

"""

# Create a scatter plot to observe the distribution of classes with time
df.plot.scatter(y='Class', x='Time',figsize=(18,4))
plt.title("Time Vs Class distribution\n", fontdict={'fontsize':20,'fontweight':5,'color':'Green'})
plt.xlabel("\nTime (Seconds)\n",fontdict={'fontsize':15,'fontweight':5,'color':'Brown'})
plt.ylabel("\nClass Type\n\n(0: No_Fraud, 1: Fraud)\n",fontdict={'fontsize':15,'fontweight':5,'color':'Brown'})
plt.show()

"""### Inferences:
Both the classes are distributed over time. Fraudulent cases are high in certain time duration whreas Non-Fraudulent transactions are distributed all the time.

"""

# Create a scatter plot to observe the distribution of classes with Amount
df.plot.scatter(y='Class', x='Amount',figsize=(18,4))
plt.title("Amount Vs Class distribution\n", fontdict={'fontsize':20,'fontweight':5,'color':'Green'})
plt.xlabel("\nAmount(Seconds)\n",fontdict={'fontsize':15,'fontweight':5,'color':'Brown'})
plt.ylabel("\nClass Type\n\n(0: No_Fraud, 1: Fraud)\n",fontdict={'fontsize':15,'fontweight':5,'color':'Brown'})
plt.show()

"""## Inferences:
- Fraudulent data denisty is higher for the amont less than 5000.
"""

# Drop unnecessary columns
df = df.drop(['Time'],axis=1)
df.head()

"""### Splitting the data into train & test data

"""

# Putting feature variable to X and response variable to y
y= df['Class']
X= df.loc[:, df.columns != 'Class']

# To split Train and Test data
from sklearn import model_selection
X_train, X_test, y_train, y_test = model_selection.train_test_split(X,y, train_size = 0.7, test_size = 0.3,
                                                                    stratify = y, random_state = 42)

"""##### Preserve X_test & y_test to evaluate on the test data once you build the model"""

# To get total of response variable, y_train, y_test variable
print("Total of response variable 'y': ",np.sum(y))
print("Total of 'y_train' variable: ", np.sum(y_train))
print("Total of 'y_test' variable: ", np.sum(y_test))

"""### Plotting the distribution of a variable"""

# Plot the histogram of a variable from the dataset to see the skewness
k=0
fig, ax = plt.subplots(7, 4, figsize=(25,35))
for i in range(7):
    for j in range(4):
        k=k+1
        sns.distplot(X_train['V'+str(k)], ax=ax[i][j])
#         ax[i][j].set_title('V'+str(k))

"""### Inferences:
- As per the above graph we can say that features are little less Gaussian and having skewness.

### If there is skewness present in the distribution use:
- <b>Power Transformer</b> package present in the <b>preprocessing library provided by sklearn</b> to make distribution more gaussian
"""

# - Apply : preprocessing.PowerTransformer(copy=False) to fit & transform the train & test data
pt= preprocessing.PowerTransformer(method='yeo-johnson', copy=True)
pt.fit(X_train)

X_train_pt = pt.transform(X_train)
X_test_pt = pt.transform(X_test)

y_train_pt = y_train
y_test_pt = y_test

# To get the shape of the train and test data
print(X_train_pt.shape)
print(y_train_pt.shape)

# plot the histogram of a variable from the dataset again to see the result
X_train_pt_df = pd.DataFrame(X_train_pt,columns=X_train.columns)
k=0
fig, ax = plt.subplots(7, 4, figsize=(25,35))
for i in range(7):
    for j in range(4):
        k=k+1
        sns.distplot(X_train_pt_df['V'+str(k)], ax=ax[i][j])
#         ax[i][j].set_title('V'+str(k))

"""### Inferences:
- After implementing power transfer features looks more gaussian.

## Model Building on Imbalanced dataset
Build different models on the imbalanced dataset and see the result

1. Logistic Regression
2. KNN
3. SVM
4. Decision Tree
5. Random Forest
6. XGBoost
"""

from sklearn import linear_model
from sklearn.neighbors import KNeighborsClassifier
from sklearn import svm
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier

from sklearn.metrics import roc_auc_score

"""Create Stratified Cross Validation Scheme

"""

# perfom cross validation on the X_train & y_train
from sklearn.model_selection import StratifiedKFold

#perform cross validation
skf = StratifiedKFold(n_splits=3, random_state=None, shuffle=False)

"""### Logistic Regression"""

# To do Logistic Regression Classifier
print("Logistic Regression Classifier: --------------------------")
for c in [0.01, 0.1, 1, 10]:
    print("C=",c, "Penalty= l2")
    cv_score_mean=0
    for train_index, test_index in skf.split(X_train_pt, y_train_pt):
        print("Train:", train_index, "Test:", test_index)
        X_train_cv, X_test_cv = X_train_pt[train_index], X_train_pt[test_index]
        y_train_cv, y_test_cv = y_train_pt.iloc[train_index], y_train_pt.iloc[test_index]

        logreg_classifier = linear_model.LogisticRegression(penalty='l2',C=c)
        logreg_classifier.fit(X_train_cv,y_train_cv)

        y_test_pred= logreg_classifier.predict_proba(X_test_cv)
        cv_score= roc_auc_score(y_true=y_test_cv,y_score=y_test_pred[:,1])
        cv_score_mean=cv_score_mean+cv_score
    print("ROC-AUC Score=", cv_score_mean/3)

"""Hyperparameter Tuning of Models to find best models

### KNN Classifier
"""

print("KNN Classifier: --------------------------")
for n_neighbor in [3,5,7]:
    print("n_neighbors=",n_neighbor)
    cv_score_mean=0
    for train_index, test_index in skf.split(X_train_pt, y_train_pt):
        print("Train:", train_index, "Test:", test_index)
        X_train_cv, X_test_cv = X_train_pt[train_index], X_train_pt[test_index]
        y_train_cv, y_test_cv = y_train_pt.iloc[train_index], y_train_pt.iloc[test_index]

        knn_classifier= KNeighborsClassifier(n_neighbors=n_neighbor)
        knn_classifier.fit(X_train_cv,y_train_cv)

        y_test_pred= knn_classifier.predict_proba(X_test_cv)
        cv_score= roc_auc_score(y_true=y_test_cv,y_score=y_test_pred[:,1])
        cv_score_mean=cv_score_mean+cv_score
    print("ROC-AUC Score=", cv_score_mean/3)

"""### SVM Classifier"""

print("SVM  Classifier: --------------------------")
for c in [1,2,3]:
    for gamma in ['auto','scale']:
        print("C=",c,"gamma=",gamma)
        cv_score_mean=0
        for train_index, test_index in skf.split(X_train_pt, y_train_pt):
            print("Train:", train_index, "Test:", test_index)
            X_train_cv, X_test_cv = X_train_pt[train_index], X_train_pt[test_index]
            y_train_cv, y_test_cv = y_train_pt.iloc[train_index], y_train_pt.iloc[test_index]

            svm_classifier= svm.SVC(C=c,gamma=gamma, probability=True)
            svm_classifier.fit(X_train_cv,y_train_cv)

            y_test_pred= svm_classifier.predict_proba(X_test_cv)
            cv_score= roc_auc_score(y_true=y_test_cv,y_score=y_test_pred[:,1])
            cv_score_mean=cv_score_mean+cv_score
        print("ROC-AUC Score=", cv_score_mean/3)

"""### Decision Tree Classifier"""

print("Decision Trees Classifier: --------------------------")
for min_samples_split in [10, 5, 2]:
    for min_samples_leaf in [10, 5, 1]:
        for max_features in ['auto','sqrt','log2',None]:
            print("min_samples_split=",min_samples_split, "min_samples_leaf=",min_samples_leaf,"max_features=",max_features)
            cv_score_mean=0
            for train_index, test_index in skf.split(X_train_pt, y_train_pt):
                print("Train:", train_index, "Test:", test_index)
                X_train_cv, X_test_cv = X_train_pt[train_index], X_train_pt[test_index]
                y_train_cv, y_test_cv = y_train_pt.iloc[train_index], y_train_pt.iloc[test_index]

                dt_classifier= DecisionTreeClassifier(min_samples_split=min_samples_split,
                                                      min_samples_leaf=min_samples_leaf,
                                                      max_features=max_features)
                dt_classifier.fit(X_train_cv,y_train_cv)

                y_test_pred= dt_classifier.predict_proba(X_test_cv)
                cv_score= roc_auc_score(y_true=y_test_cv,y_score=y_test_pred[:,1])
                cv_score_mean=cv_score_mean+cv_score
            print("ROC-AUC Score=", cv_score_mean/3)

"""### Random Forest Classifier"""

print("Random Forest Classifier: --------------------------")
for n_estimators in [100,150,200]:
    for min_samples_leaf in [10,5,1]:
        for max_features in ['auto','sqrt','log2',None]:
            print("n_estimators=",n_estimators, "min_samples_leaf=",min_samples_leaf,"max_features=",max_features)
            cv_score_mean=0
            for train_index, test_index in skf.split(X_train_pt, y_train_pt):
                print("Train:", train_index, "Test:", test_index)
                X_train_cv, X_test_cv = X_train_pt[train_index], X_train_pt[test_index]
                y_train_cv, y_test_cv = y_train_pt.iloc[train_index], y_train_pt.iloc[test_index]

                rf_classifier= RandomForestClassifier(n_estimators=n_estimators,
                                                      min_samples_leaf=min_samples_leaf,
                                                      max_features=max_features, n_jobs=-1)
                rf_classifier.fit(X_train_cv,y_train_cv)

                y_test_pred= rf_classifier.predict_proba(X_test_cv)
                cv_score= roc_auc_score(y_true=y_test_cv,y_score=y_test_pred[:,1])
                cv_score_mean=cv_score_mean+cv_score
            print("ROC-AUC Score=", cv_score_mean/3)

"""### XG Boost Classifier"""

print("XGBOOST Classifier: --------------------------")
for learning_rate in [0.2,0.6]:
    for subsample in [0.3, 0.6, 0.9]:
        print("learning_rate=",learning_rate, "subsample=",subsample)
        cv_score_mean=0
        for train_index, test_index in skf.split(X_train_pt, y_train_pt):
            print("Train:", train_index, "Test:", test_index)
            X_train_cv, X_test_cv = X_train_pt[train_index], X_train_pt[test_index]
            y_train_cv, y_test_cv = y_train_pt.iloc[train_index], y_train_pt.iloc[test_index]

            xgboost_classifier= XGBClassifier(n_estimators=200,
                                            learning_rate=learning_rate,
                                            subsample=subsample, n_jobs=-1)
            xgboost_classifier.fit(X_train_cv,y_train_cv)

            y_test_pred= xgboost_classifier.predict_proba(X_test_cv)
            cv_score= roc_auc_score(y_true=y_test_cv,y_score=y_test_pred[:,1])
            cv_score_mean=cv_score_mean+cv_score
        print("ROC-AUC Score=", cv_score_mean/3)

"""### Cross Validation ROC-AUC Score of the models and best hyperparameters on Imbalanced data

*   LogisticRegression(penalty='l2',C=0.01) = 0.981995637510146
*   KNeighborsClassifier(n_neighbors=7) = 0.9300266801223783
* svm.SVC(C=1,gamma='auto', probability=True) = 0.9612595957414826
*   DecisionTreeClassifier(min_samples_split=2,min_samples_leaf=10,max_features=None) = 0.9269609164616767
* RandomForestClassifier(n_estimators=150,                                                  min_samples_leaf=10,                                         max_features='log2')=0.9693891396983281
*XGBClassifier(n_estimators=200,learning_rate=0.2,subsample=0.6, n_jobs=-1) =0.9792456802634971

#### Proceed with the model which shows the best result
- Apply the best hyperparameter on the model
- Predict on the test dataset
"""

#Initialise the model with optimum hyperparameters
clf = linear_model.LogisticRegression(penalty='l2',C=0.01)
clf.fit(X_train, y_train)
#predict on test to give probability
y_pred= clf.predict_proba(X_test)
#calculate the ROC-AUC
score= roc_auc_score(y_true=y_test,y_score=y_pred[:,1])
print("LogisticRegression ROC-AUC Score =", score)

clf = KNeighborsClassifier(n_neighbors=7)
clf.fit(X_train, y_train)
y_pred= clf.predict_proba(X_test)
score= roc_auc_score(y_true=y_test,y_score=y_pred[:,1])
print("KNeighbors Classifier ROC-AUC Score =", score)

clf = svm.SVC(C=1,gamma='auto', probability=True)
clf.fit(X_train, y_train)
y_pred= clf.predict_proba(X_test)
score= roc_auc_score(y_true=y_test,y_score=y_pred[:,1])
print("SVM Classifier ROC-AUC Score =", score)

clf = DecisionTreeClassifier(min_samples_split=2,min_samples_leaf=10,max_features=None)
clf.fit(X_train, y_train)
y_pred= clf.predict_proba(X_test)
score= roc_auc_score(y_true=y_test,y_score=y_pred[:,1])
print("Decision Tree Classifier ROC-AUC Score =", score)

clf = RandomForestClassifier(n_estimators=150, min_samples_leaf=10, max_features='log2')
clf.fit(X_train, y_train)
y_pred= clf.predict_proba(X_test)
score= roc_auc_score(y_true=y_test,y_score=y_pred[:,1])
print("Random Forest Classifier ROC-AUC Score =", score)

clf = XGBClassifier(n_estimators=200,learning_rate=0.2,subsample=0.6, n_jobs=-1)
clf.fit(X_train, y_train)
y_pred= clf.predict_proba(X_test)
score= roc_auc_score(y_true=y_test,y_score=y_pred[:,1])
print("XGBOOST Classifier ROC-AUC Score =", score)

"""### Print the important features of the best model to understand the dataset
- This will not give much explanation on the already transformed dataset
- But it will help us in understanding if the dataset is not PCA transformed
"""

# Commented out IPython magic to ensure Python compatibility.
# To get the important features
var_imp = []
for i in clf.feature_importances_:
    var_imp.append(i)
print('Top var =', var_imp.index(np.sort(clf.feature_importances_)[-1])+1)
print('2nd Top var =', var_imp.index(np.sort(clf.feature_importances_)[-2])+1)
print('3rd Top var =', var_imp.index(np.sort(clf.feature_importances_)[-3])+1)

# Variable on Index-16 and Index-13 seems to be the top 2 variables
top_var_index = var_imp.index(np.sort(clf.feature_importances_)[-1])
second_top_var_index = var_imp.index(np.sort(clf.feature_importances_)[-2])

X_train_1 = X_train.to_numpy()[np.where(y_train==1.0)]
X_train_0 = X_train.to_numpy()[np.where(y_train==0.0)]

np.random.shuffle(X_train_0)

import matplotlib.pyplot as plt
# %matplotlib inline
plt.rcParams['figure.figsize'] = [20, 20]

plt.scatter(X_train_1[:, top_var_index], X_train_1[:, second_top_var_index], label='Actual Class-1 Examples')
plt.scatter(X_train_0[:X_train_1.shape[0], top_var_index], X_train_0[:X_train_1.shape[0], second_top_var_index],
            label='Actual Class-0 Examples')
plt.legend()
plt.show()

"""## Model building with balancing Classes

##### Perform class balancing with :
- Random Oversampling
- SMOTE
- ADASYN

### Random Oversampling
- Build different models on the balanced dataset and see the result
"""

from sklearn import linear_model
from sklearn.neighbors import KNeighborsClassifier
from sklearn import svm
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier

from sklearn.metrics import roc_auc_score
from imblearn import over_sampling
from imblearn.over_sampling import RandomOverSampler

# perfom cross validation on the X_train & y_train
from sklearn.model_selection import StratifiedKFold

#perform cross validation
skf = StratifiedKFold(n_splits=3, random_state=None, shuffle=False)

print("Logistic Regression Classifier: --------------------------")
for c in [0.01, 0.1, 1]:
    print("C=",c, "Penalty= l2")
    cv_score_mean=0
    for train_index, test_index in skf.split(X_train_pt, y_train_pt):
        print("Train:", train_index, "Test:", test_index)
        X_train_cv, X_test_cv = X_train_pt[train_index], X_train_pt[test_index]
        y_train_cv, y_test_cv = y_train_pt.iloc[train_index], y_train_pt.iloc[test_index]

        ros = RandomOverSampler(sampling_strategy='minority', random_state=42)
        X_ros_cv,y_ros_cv = ros.fit_resample(X_train_cv,y_train_cv)

        logreg_classifier = linear_model.LogisticRegression(penalty='l2',C=c)
        logreg_classifier.fit(X_ros_cv,y_ros_cv)

        y_test_pred= logreg_classifier.predict_proba(X_test_cv)
        cv_score= roc_auc_score(y_true=y_test_cv,y_score=y_test_pred[:,1])
        cv_score_mean=cv_score_mean+cv_score
    print("ROC-AUC Score=", cv_score_mean/3)

"""Check the improvement in cross validation ROC-AUC score of other models

"""

print("KNN Classifier: --------------------------")
cv_score_mean=0
for train_index, test_index in skf.split(X_train_pt, y_train_pt):
    print("Train:", train_index, "Test:", test_index)
    X_train_cv, X_test_cv = X_train_pt[train_index], X_train_pt[test_index]
    y_train_cv, y_test_cv = y_train_pt.iloc[train_index], y_train_pt.iloc[test_index]

    ros = RandomOverSampler(sampling_strategy='minority', random_state=42)
    X_ros_cv,y_ros_cv = ros.fit_resample(X_train_cv,y_train_cv)

    knn_classifier= KNeighborsClassifier(n_neighbors=7,n_jobs=-1)
    knn_classifier.fit(X_ros_cv,y_ros_cv)

    y_test_pred= knn_classifier.predict_proba(X_test_cv)
    cv_score= roc_auc_score(y_true=y_test_cv,y_score=y_test_pred[:,1])
    cv_score_mean=cv_score_mean+cv_score
print("ROC-AUC Score=", cv_score_mean/3)

print("SVM  Classifier: --------------------------")
cv_score_mean=0
for train_index, test_index in skf.split(X_train_pt, y_train_pt):
    print("Train:", train_index, "Test:", test_index)
    X_train_cv, X_test_cv = X_train_pt[train_index], X_train_pt[test_index]
    y_train_cv, y_test_cv = y_train_pt.iloc[train_index], y_train_pt.iloc[test_index]

    ros = RandomOverSampler(sampling_strategy='minority', random_state=42)
    X_ros_cv,y_ros_cv = ros.fit_resample(X_train_cv,y_train_cv)

    svm_classifier= svm.SVC(C=1,gamma='auto', probability=True)
    svm_classifier.fit(X_ros_cv,y_ros_cv)

    y_test_pred= svm_classifier.predict_proba(X_test_cv)
    cv_score= roc_auc_score(y_true=y_test_cv,y_score=y_test_pred[:,1])
    cv_score_mean=cv_score_mean+cv_score
print("ROC-AUC Score=", cv_score_mean/3)

print("Decision Trees Classifier: --------------------------")
cv_score_mean=0
for train_index, test_index in skf.split(X_train_pt, y_train_pt):
    print("Train:", train_index, "Test:", test_index)
    X_train_cv, X_test_cv = X_train_pt[train_index], X_train_pt[test_index]
    y_train_cv, y_test_cv = y_train_pt.iloc[train_index], y_train_pt.iloc[test_index]

    ros = RandomOverSampler(sampling_strategy='minority', random_state=42)
    X_ros_cv,y_ros_cv = ros.fit_resample(X_train_cv,y_train_cv)

    dt_classifier= DecisionTreeClassifier(min_samples_split=2,
                                        min_samples_leaf=10,
                                        max_features=None)
    dt_classifier.fit(X_ros_cv,y_ros_cv)

    y_test_pred= dt_classifier.predict_proba(X_test_cv)
    cv_score= roc_auc_score(y_true=y_test_cv,y_score=y_test_pred[:,1])
    cv_score_mean=cv_score_mean+cv_score
print("ROC-AUC Score=", cv_score_mean/3)

print("Random Forest Classifier: --------------------------")
cv_score_mean=0
for train_index, test_index in skf.split(X_train_pt, y_train_pt):
    print("Train:", train_index, "Test:", test_index)
    X_train_cv, X_test_cv = X_train_pt[train_index], X_train_pt[test_index]
    y_train_cv, y_test_cv = y_train_pt.iloc[train_index], y_train_pt.iloc[test_index]

    ros = RandomOverSampler(sampling_strategy='minority', random_state=42)
    X_ros_cv,y_ros_cv = ros.fit_resample(X_train_cv,y_train_cv)

    rf_classifier= RandomForestClassifier(n_estimators=150,
                                        min_samples_leaf=10,
                                        max_features='log2', n_jobs=-1)
    rf_classifier.fit(X_ros_cv,y_ros_cv)

    y_test_pred= rf_classifier.predict_proba(X_test_cv)
    cv_score= roc_auc_score(y_true=y_test_cv,y_score=y_test_pred[:,1])
    cv_score_mean=cv_score_mean+cv_score
print("ROC-AUC Score=", cv_score_mean/3)

print("XGBOOST Classifier: --------------------------")
cv_score_mean=0
for train_index, test_index in skf.split(X_train_pt, y_train_pt):
    print("Train:", train_index, "Test:", test_index)
    X_train_cv, X_test_cv = X_train_pt[train_index], X_train_pt[test_index]
    y_train_cv, y_test_cv = y_train_pt.iloc[train_index], y_train_pt.iloc[test_index]

    ros = RandomOverSampler(sampling_strategy='minority', random_state=42)
    X_ros_cv,y_ros_cv = ros.fit_resample(X_train_cv,y_train_cv)

    xgboost_classifier= XGBClassifier(n_estimators=200,
                                    learning_rate=0.2,
                                    subsample=0.6, n_jobs=-1)
    xgboost_classifier.fit(X_ros_cv,y_ros_cv)

    y_test_pred= xgboost_classifier.predict_proba(X_test_cv)
    cv_score= roc_auc_score(y_true=y_test_cv,y_score=y_test_pred[:,1])
    cv_score_mean=cv_score_mean+cv_score
print("ROC-AUC Score=", cv_score_mean/3)

"""### Cross Validation ROC-AUC Score after Random Oversampling
* LogisticRegression(penalty='l2',C=0.01) = 0.9786819703350383
* KNeighborsClassifier(n_neighbors=7) = 0.9299831290025934
* svm.SVC(C=1,gamma='auto', probability=True) = `Not computed due to large training time`
* DecisionTreeClassifier(min_samples_split=2,min_samples_leaf=10,max_features=None) = 0.8994711914467848
* RandomForestClassifier(n_estimators=150, min_samples_leaf=10, max_features='log2')=0.9653169027471836
* XGBClassifier(n_estimators=200,learning_rate=0.2,subsample=0.6, n_jobs=-1) =0.9795906252613396

All the models score decreased after Random Oversampling. Only XGBOOST score increases after Oversampling.

### Print the class distribution after applying SMOTE
"""

import warnings
warnings.filterwarnings("ignore")


sm = over_sampling.SMOTE(random_state=0)
X_train_smote, y_train_smote = sm.fit_resample(X_train, y_train)
# Artificial minority samples and corresponding minority labels from SMOTE are appended
# below X_train and y_train respectively
# So to exclusively get the artificial minority samples from SMOTE, we do
X_train_smote_1 = X_train_smote[X_train.shape[0]:]

X_train_1 = X_train.to_numpy()[np.where(y_train==1.0)]
X_train_0 = X_train.to_numpy()[np.where(y_train==0.0)]


plt.rcParams['figure.figsize'] = [20, 20]
fig = plt.figure()

plt.subplot(3, 1, 1)
plt.scatter(X_train_1[:, 0], X_train_1[:, 1], label='Actual Class-1 Examples')
plt.legend()

plt.subplot(3, 1, 2)
plt.scatter(X_train_1[:, 0], X_train_1[:, 1], label='Actual Class-1 Examples')
plt.scatter(X_train_smote_1[:X_train_1.shape[0], 0], X_train_smote_1[:X_train_1.shape[0], 1],
            label='Artificial SMOTE Class-1 Examples')
plt.legend()

plt.subplot(3, 1, 3)
plt.scatter(X_train_1[:, 0], X_train_1[:, 1], label='Actual Class-1 Examples')
plt.scatter(X_train_0[:X_train_1.shape[0], 0], X_train_0[:X_train_1.shape[0], 1], label='Actual Class-0 Examples')
plt.legend()
plt.show()

print("Logistic Regression Classifier: --------------------------")
cv_score_mean=0
for train_index, test_index in skf.split(X_train_pt, y_train_pt):
    print("Train:", train_index, "Test:", test_index)
    X_train_cv, X_test_cv = X_train_pt[train_index], X_train_pt[test_index]
    y_train_cv, y_test_cv = y_train_pt.iloc[train_index], y_train_pt.iloc[test_index]

    ros = over_sampling.SMOTE(sampling_strategy='minority', random_state=42)
    X_ros_cv,y_ros_cv = ros.fit_resample(X_train_cv,y_train_cv)

    logreg_classifier = linear_model.LogisticRegression(penalty='l2',C=0.01)
    logreg_classifier.fit(X_ros_cv,y_ros_cv)

    y_test_pred= logreg_classifier.predict_proba(X_test_cv)
    cv_score= roc_auc_score(y_true=y_test_cv,y_score=y_test_pred[:,1])
    cv_score_mean=cv_score_mean+cv_score
print("ROC-AUC Score=", cv_score_mean/3)

print("KNN Classifier: --------------------------")
cv_score_mean=0
for train_index, test_index in skf.split(X_train_pt, y_train_pt):
    print("Train:", train_index, "Test:", test_index)
    X_train_cv, X_test_cv = X_train_pt[train_index], X_train_pt[test_index]
    y_train_cv, y_test_cv = y_train_pt.iloc[train_index], y_train_pt.iloc[test_index]

    ros = over_sampling.SMOTE(sampling_strategy='minority', random_state=42)
    X_ros_cv,y_ros_cv = ros.fit_resample(X_train_cv,y_train_cv)

    knn_classifier= KNeighborsClassifier(n_neighbors=7,n_jobs=-1)
    knn_classifier.fit(X_ros_cv,y_ros_cv)

    y_test_pred= knn_classifier.predict_proba(X_test_cv)
    cv_score= roc_auc_score(y_true=y_test_cv,y_score=y_test_pred[:,1])
    cv_score_mean=cv_score_mean+cv_score
print("ROC-AUC Score=", cv_score_mean/3)

print("Decision Trees Classifier: --------------------------")
cv_score_mean=0
for train_index, test_index in skf.split(X_train_pt, y_train_pt):
    print("Train:", train_index, "Test:", test_index)
    X_train_cv, X_test_cv = X_train_pt[train_index], X_train_pt[test_index]
    y_train_cv, y_test_cv = y_train_pt.iloc[train_index], y_train_pt.iloc[test_index]

    ros = over_sampling.SMOTE(sampling_strategy='minority', random_state=42)
    X_ros_cv,y_ros_cv = ros.fit_resample(X_train_cv,y_train_cv)

    dt_classifier= DecisionTreeClassifier(min_samples_split=2,
                                        min_samples_leaf=10,
                                        max_features=None)
    dt_classifier.fit(X_ros_cv,y_ros_cv)

    y_test_pred= dt_classifier.predict_proba(X_test_cv)
    cv_score= roc_auc_score(y_true=y_test_cv,y_score=y_test_pred[:,1])
    cv_score_mean=cv_score_mean+cv_score
print("ROC-AUC Score=", cv_score_mean/3)

print("Random Forest Classifier: --------------------------")
cv_score_mean=0
for train_index, test_index in skf.split(X_train_pt, y_train_pt):
    print("Train:", train_index, "Test:", test_index)
    X_train_cv, X_test_cv = X_train_pt[train_index], X_train_pt[test_index]
    y_train_cv, y_test_cv = y_train_pt.iloc[train_index], y_train_pt.iloc[test_index]

    ros = over_sampling.SMOTE(sampling_strategy='minority', random_state=42)
    X_ros_cv,y_ros_cv = ros.fit_resample(X_train_cv,y_train_cv)

    rf_classifier= RandomForestClassifier(n_estimators=150,
                                        min_samples_leaf=10,
                                        max_features='log2', n_jobs=-1)
    rf_classifier.fit(X_ros_cv,y_ros_cv)

    y_test_pred= rf_classifier.predict_proba(X_test_cv)
    cv_score= roc_auc_score(y_true=y_test_cv,y_score=y_test_pred[:,1])
    cv_score_mean=cv_score_mean+cv_score
print("ROC-AUC Score=", cv_score_mean/3)

print("XGBOOST Classifier: --------------------------")
cv_score_mean=0
for train_index, test_index in skf.split(X_train_pt, y_train_pt):
    print("Train:", train_index, "Test:", test_index)
    X_train_cv, X_test_cv = X_train_pt[train_index], X_train_pt[test_index]
    y_train_cv, y_test_cv = y_train_pt.iloc[train_index], y_train_pt.iloc[test_index]

    ros = over_sampling.SMOTE(sampling_strategy='minority', random_state=42)
    X_ros_cv,y_ros_cv = ros.fit_resample(X_train_cv,y_train_cv)

    xgboost_classifier= XGBClassifier(n_estimators=200,
                                    learning_rate=0.2,
                                    subsample=0.6, n_jobs=-1)
    xgboost_classifier.fit(X_ros_cv,y_ros_cv)

    y_test_pred= xgboost_classifier.predict_proba(X_test_cv)
    cv_score= roc_auc_score(y_true=y_test_cv,y_score=y_test_pred[:,1])
    cv_score_mean=cv_score_mean+cv_score
print("ROC-AUC Score=", cv_score_mean/3)

print("SVM  Classifier: --------------------------")
cv_score_mean=0
for train_index, test_index in skf.split(X_train_pt, y_train_pt):
    print("Train:", train_index, "Test:", test_index)
    X_train_cv, X_test_cv = X_train_pt[train_index], X_train_pt[test_index]
    y_train_cv, y_test_cv = y_train_pt.iloc[train_index], y_train_pt.iloc[test_index]

    ros = over_sampling.SMOTE(sampling_strategy='minority', random_state=42)
    X_ros_cv,y_ros_cv = ros.fit_resample(X_train_cv,y_train_cv)

    svm_classifier= svm.SVC(C=1,gamma='auto', probability=True)
    svm_classifier.fit(X_ros_cv,y_ros_cv)

    y_test_pred= svm_classifier.predict_proba(X_test_cv)
    cv_score= roc_auc_score(y_true=y_test_cv,y_score=y_test_pred[:,1])
    cv_score_mean=cv_score_mean+cv_score
print("ROC-AUC Score=", cv_score_mean/3)

"""### Cross Validation ROC-AUC Score after SMOTE
* LogisticRegression(penalty='l2',C=0.01) = 0.9767161835173893
* KNeighborsClassifier(n_neighbors=7) = 0.9442219242710334
* svm.SVC(C=1,gamma='auto', probability=True) = `Not computed due to large training time`
* DecisionTreeClassifier(min_samples_split=2,min_samples_leaf=10,max_features=None) = 0.9187106612638388
* RandomForestClassifier(n_estimators=150, min_samples_leaf=10, max_features='log2')=0.9824563994388676
* XGBClassifier(n_estimators=200,learning_rate=0.2,subsample=0.6, n_jobs=-1) =0.0.9743278979662436

All the models score `Increased` after SMOTE. Only Logistic Regression score decreases after SMOTE.

### Print the class distribution after applying ADASYN
"""

# Commented out IPython magic to ensure Python compatibility.
import warnings
warnings.filterwarnings("ignore")

from imblearn import over_sampling

ada = over_sampling.ADASYN(random_state=0)
X_train_adasyn, y_train_adasyn = ada.fit_resample(X_train, y_train)
# Artificial minority samples and corresponding minority labels from ADASYN are appended
# below X_train and y_train respectively
# So to exclusively get the artificial minority samples from ADASYN, we do
X_train_adasyn_1 = X_train_adasyn[X_train.shape[0]:]

X_train_1 = X_train.to_numpy()[np.where(y_train==1.0)]
X_train_0 = X_train.to_numpy()[np.where(y_train==0.0)]



import matplotlib.pyplot as plt
# %matplotlib inline
plt.rcParams['figure.figsize'] = [20, 20]
fig = plt.figure()

plt.subplot(3, 1, 1)
plt.scatter(X_train_1[:, 0], X_train_1[:, 1], label='Actual Class-1 Examples')
plt.legend()

plt.subplot(3, 1, 2)
plt.scatter(X_train_1[:, 0], X_train_1[:, 1], label='Actual Class-1 Examples')
plt.scatter(X_train_adasyn_1[:X_train_1.shape[0], 0], X_train_adasyn_1[:X_train_1.shape[0], 1],
            label='Artificial ADASYN Class-1 Examples')
plt.legend()

plt.subplot(3, 1, 3)
plt.scatter(X_train_1[:, 0], X_train_1[:, 1], label='Actual Class-1 Examples')
plt.scatter(X_train_0[:X_train_1.shape[0], 0], X_train_0[:X_train_1.shape[0], 1], label='Actual Class-0 Examples')
plt.legend()
plt.show()

print("Logistic Regression Classifier: --------------------------")
cv_score_mean=0
for train_index, test_index in skf.split(X_train_pt, y_train_pt):
    print("Train:", train_index, "Test:", test_index)
    X_train_cv, X_test_cv = X_train_pt[train_index], X_train_pt[test_index]
    y_train_cv, y_test_cv = y_train_pt.iloc[train_index], y_train_pt.iloc[test_index]

    ros = over_sampling.ADASYN(sampling_strategy='minority', random_state=42)
    X_ros_cv,y_ros_cv = ros.fit_resample(X_train_cv,y_train_cv)

    logreg_classifier = linear_model.LogisticRegression(penalty='l2',C=0.01)
    logreg_classifier.fit(X_ros_cv,y_ros_cv)

    y_test_pred= logreg_classifier.predict_proba(X_test_cv)
    cv_score= roc_auc_score(y_true=y_test_cv,y_score=y_test_pred[:,1])
    cv_score_mean=cv_score_mean+cv_score
print("ROC-AUC Score=", cv_score_mean/3)

print("KNN Classifier: --------------------------")
cv_score_mean=0
for train_index, test_index in skf.split(X_train_pt, y_train_pt):
    print("Train:", train_index, "Test:", test_index)
    X_train_cv, X_test_cv = X_train_pt[train_index], X_train_pt[test_index]
    y_train_cv, y_test_cv = y_train_pt.iloc[train_index], y_train_pt.iloc[test_index]

    ros = over_sampling.ADASYN(sampling_strategy='minority', random_state=42)
    X_ros_cv,y_ros_cv = ros.fit_resample(X_train_cv,y_train_cv)

    knn_classifier= KNeighborsClassifier(n_neighbors=7,n_jobs=-1)
    knn_classifier.fit(X_ros_cv,y_ros_cv)

    y_test_pred= knn_classifier.predict_proba(X_test_cv)
    cv_score= roc_auc_score(y_true=y_test_cv,y_score=y_test_pred[:,1])
    cv_score_mean=cv_score_mean+cv_score
print("ROC-AUC Score=", cv_score_mean/3)

print("Decision Trees Classifier: --------------------------")
cv_score_mean=0
for train_index, test_index in skf.split(X_train_pt, y_train_pt):
    print("Train:", train_index, "Test:", test_index)
    X_train_cv, X_test_cv = X_train_pt[train_index], X_train_pt[test_index]
    y_train_cv, y_test_cv = y_train_pt.iloc[train_index], y_train_pt.iloc[test_index]

    ros = over_sampling.ADASYN(sampling_strategy='minority', random_state=42)
    X_ros_cv,y_ros_cv = ros.fit_resample(X_train_cv,y_train_cv)

    dt_classifier= DecisionTreeClassifier(min_samples_split=2,
                                        min_samples_leaf=10,
                                        max_features=None)
    dt_classifier.fit(X_ros_cv,y_ros_cv)

    y_test_pred= dt_classifier.predict_proba(X_test_cv)
    cv_score= roc_auc_score(y_true=y_test_cv,y_score=y_test_pred[:,1])
    cv_score_mean=cv_score_mean+cv_score
print("ROC-AUC Score=", cv_score_mean/3)

print("Random Forest Classifier: --------------------------")
cv_score_mean=0
for train_index, test_index in skf.split(X_train_pt, y_train_pt):
    print("Train:", train_index, "Test:", test_index)
    X_train_cv, X_test_cv = X_train_pt[train_index], X_train_pt[test_index]
    y_train_cv, y_test_cv = y_train_pt.iloc[train_index], y_train_pt.iloc[test_index]

    ros = over_sampling.ADASYN(sampling_strategy='minority', random_state=42)
    X_ros_cv,y_ros_cv = ros.fit_resample(X_train_cv,y_train_cv)

    rf_classifier= RandomForestClassifier(n_estimators=150,
                                        min_samples_leaf=10,
                                        max_features='log2', n_jobs=-1)
    rf_classifier.fit(X_ros_cv,y_ros_cv)

    y_test_pred= rf_classifier.predict_proba(X_test_cv)
    cv_score= roc_auc_score(y_true=y_test_cv,y_score=y_test_pred[:,1])
    cv_score_mean=cv_score_mean+cv_score
print("ROC-AUC Score=", cv_score_mean/3)

print("XGBOOST Classifier: --------------------------")
cv_score_mean=0
for train_index, test_index in skf.split(X_train_pt, y_train_pt):
    print("Train:", train_index, "Test:", test_index)
    X_train_cv, X_test_cv = X_train_pt[train_index], X_train_pt[test_index]
    y_train_cv, y_test_cv = y_train_pt.iloc[train_index], y_train_pt.iloc[test_index]

    ros = over_sampling.ADASYN(sampling_strategy='minority', random_state=42)
    X_ros_cv,y_ros_cv = ros.fit_resample(X_train_cv,y_train_cv)

    xgboost_classifier= XGBClassifier(n_estimators=200,
                                    learning_rate=0.2,
                                    subsample=0.6, n_jobs=-1)
    xgboost_classifier.fit(X_ros_cv,y_ros_cv)

    y_test_pred= xgboost_classifier.predict_proba(X_test_cv)
    cv_score= roc_auc_score(y_true=y_test_cv,y_score=y_test_pred[:,1])
    cv_score_mean=cv_score_mean+cv_score
print("ROC-AUC Score=", cv_score_mean/3)

print("SVM  Classifier: --------------------------")
cv_score_mean=0
for train_index, test_index in skf.split(X_train_pt, y_train_pt):
    print("Train:", train_index, "Test:", test_index)
    X_train_cv, X_test_cv = X_train_pt[train_index], X_train_pt[test_index]
    y_train_cv, y_test_cv = y_train_pt.iloc[train_index], y_train_pt.iloc[test_index]

    ros = over_sampling.ADASYN(sampling_strategy='minority', random_state=42)
    X_ros_cv,y_ros_cv = ros.fit_resample(X_train_cv,y_train_cv)

    svm_classifier= svm.SVC(C=1,gamma='auto', probability=True)
    svm_classifier.fit(X_ros_cv,y_ros_cv)

    y_test_pred= svm_classifier.predict_proba(X_test_cv)
    cv_score= roc_auc_score(y_true=y_test_cv,y_score=y_test_pred[:,1])
    cv_score_mean=cv_score_mean+cv_score
print("ROC-AUC Score=", cv_score_mean/3)

"""### Cross Validation ROC-AUC Score after ADASYN
* LogisticRegression(penalty='l2',C=0.01) = 0.9735984516349793
* KNeighborsClassifier(n_neighbors=7) = 0.9442031624295432
* svm.SVC(C=1,gamma='auto', probability=True) = `Not computed due to large training time`
* DecisionTreeClassifier(min_samples_split=2,min_samples_leaf=10,max_features=None) = 0.9129774246209171
* RandomForestClassifier(n_estimators=150, min_samples_leaf=10, max_features='log2')=0.9791655588355481
* XGBClassifier(n_estimators=200,learning_rate=0.2,subsample=0.6, n_jobs=-1) =0.0.9716583354163855

All the models score `Increased` after ADASYN . Only Logistic Regression and XGBOOST score decreases after ADASYN.

### Select the oversampling method which shows the best result on a model

### Random Oversampling best models
* LogisticRegression
* XGBClassifier

### SMOTE best models
* KNeighborsClassifier
* DecisionTreeClassifier
* RandomForestClassifier

### Use the best models to Predict on the test dataset
"""

# perform the best oversampling method on X_train & y_train

#initialise the model with optimum hyperparameters
clf = linear_model.LogisticRegression(penalty='l2',C=0.01)
#oversampling method
ros = over_sampling.RandomOverSampler(sampling_strategy='minority', random_state=42)
X_ros,y_ros = ros.fit_resample(X_train,y_train)
clf.fit(X_ros,y_ros)
#predict on test to give probability
y_pred= clf.predict_proba(X_test)
#calculate the ROC-AUC
score= roc_auc_score(y_true=y_test,y_score=y_pred[:,1])
print("LogisticRegression ROC-AUC Score =", score)

clf = KNeighborsClassifier(n_neighbors=7)
ros = over_sampling.SMOTE(sampling_strategy='minority', random_state=42)
X_ros,y_ros = ros.fit_resample(X_train,y_train)
clf.fit(X_ros,y_ros)
y_pred= clf.predict_proba(X_test)
score= roc_auc_score(y_true=y_test,y_score=y_pred[:,1])
print("KNeighbors Classifier ROC-AUC Score =", score)

clf = DecisionTreeClassifier(min_samples_split=2,min_samples_leaf=10,max_features=None)
ros = over_sampling.SMOTE(sampling_strategy='minority', random_state=42)
X_ros,y_ros = ros.fit_resample(X_train,y_train)
clf.fit(X_ros,y_ros)
y_pred= clf.predict_proba(X_test)
score= roc_auc_score(y_true=y_test,y_score=y_pred[:,1])
print("Decision Tree Classifier ROC-AUC Score =", score)

clf = RandomForestClassifier(n_estimators=150, min_samples_leaf=10, max_features='log2')
ros = over_sampling.SMOTE(sampling_strategy='minority', random_state=42)
X_ros,y_ros = ros.fit_resample(X_train,y_train)
clf.fit(X_ros,y_ros)
y_pred= clf.predict_proba(X_test)
score= roc_auc_score(y_true=y_test,y_score=y_pred[:,1])
print("Random Forest Classifier ROC-AUC Score =", score)

"""Best Model is XGBOOST CLassifier with Random Oversampling"""

clf = XGBClassifier(n_estimators=200,learning_rate=0.2,subsample=0.6, n_jobs=-1)
ros = over_sampling.RandomOverSampler(sampling_strategy='minority', random_state=42)
X_ros,y_ros = ros.fit_resample(X_train,y_train)
clf.fit(X_ros,y_ros)
y_pred= clf.predict_proba(X_test.values)
score= roc_auc_score(y_true=y_test,y_score=y_pred[:,1])
print("XGBOOST Classifier ROC-AUC Score =", score)

"""### Print the important features of the best model to understand the dataset"""

# Commented out IPython magic to ensure Python compatibility.
var_imp = []
for i in clf.feature_importances_:
    var_imp.append(i)
print('Top var =', var_imp.index(np.sort(clf.feature_importances_)[-1])+1)
print('2nd Top var =', var_imp.index(np.sort(clf.feature_importances_)[-2])+1)
print('3rd Top var =', var_imp.index(np.sort(clf.feature_importances_)[-3])+1)

# Variable on Index-13 and Index-9 seems to be the top 2 variables
top_var_index = var_imp.index(np.sort(clf.feature_importances_)[-1])
second_top_var_index = var_imp.index(np.sort(clf.feature_importances_)[-2])

X_train_1 = X_train.to_numpy()[np.where(y_train==1.0)]
X_train_0 = X_train.to_numpy()[np.where(y_train==0.0)]

np.random.shuffle(X_train_0)

import matplotlib.pyplot as plt
# %matplotlib inline
plt.rcParams['figure.figsize'] = [20, 20]

plt.scatter(X_train_1[:, top_var_index], X_train_1[:, second_top_var_index], label='Actual Class-1 Examples')
plt.scatter(X_train_0[:X_train_1.shape[0], top_var_index], X_train_0[:X_train_1.shape[0], second_top_var_index],
            label='Actual Class-0 Examples')
plt.legend()
plt.show()

"""## To choose the best threshold

Create a data frame with columns "actual_label" and "predicted_prob" on training data
"""

y_train_pred= clf.predict_proba(X_train.values)
y_df = pd.DataFrame({'actual_label':y_train, 'predicted_prob':y_train_pred[:,1]})
y_df.head()

# find the best threshold best on roc_curve to know the range for search
fpr, tpr, thresholds = metrics.roc_curve(y_train, y_train_pred[:,1])
threshold = thresholds[np.argmax(tpr-fpr)]
print(threshold)

# Let's create columns with different probability cutoffs
thresholds = [0.99,0.988,0.9875,0.987,0.986,0.98,0.97,0.9,0.8]
for i in thresholds:
    y_df[i]= y_df.predicted_prob.map(lambda x: 1 if x > i else 0)
y_df.head()

# calculate Precision and Recall  for various probability cutoffs.
cutoff_df = pd.DataFrame( columns = ['prob','precision','recall'])
from sklearn.metrics import confusion_matrix

thresholds = [0.99,0.988,0.9875,0.987,0.986,0.98,0.97,0.9,0.8]
for i in thresholds:
    cm = metrics.confusion_matrix(y_df.actual_label, y_df[i])
    total=sum(sum(cm))
    precision = cm[1,1]/(cm[1,1]+cm[0,1])
    recall =  cm[1,1]/(cm[1,1]+cm[1,0])

    cutoff_df.loc[i] =[i ,precision,recall]
print(cutoff_df)

# f1 = (2*precision*recall)/(precision+recall)
f1 = (2*0.994203*0.997093)/(0.994203+0.997093)
print(f1)

"""### Inferences:
-The Threshold of "0.9880" gives a Precision of 99.42% and F1 Score of 99.56% on Training data. Let see these scores on test

"""

y_test_pred= clf.predict_proba(X_test.values)
y_df = pd.DataFrame({'actual_label':y_test, 'predicted_prob':y_test_pred[:,1]})
y_df['predicted_label']= y_df.predicted_prob.map(lambda x: 1 if x > 0.9880 else 0)
y_df.head()

cm = metrics.confusion_matrix(y_df.actual_label, y_df.predicted_label)
precision = cm[1,1]/(cm[1,1]+cm[0,1])
recall =  cm[1,1]/(cm[1,1]+cm[1,0])
f1 = (2*precision*recall)/(precision+recall)

print("Precision:",precision)
print("Recall:",recall)
print("F1 Score:",f1)

"""### Conclusion:
We can use the above threshold as High Precision is good in predicting "Actual possitives as True Possitives". Thus helping the bank in not wasting resources identifying a fraud.

### End  of Credit Card Fraud Detection
"""